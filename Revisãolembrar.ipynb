{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHjyddkTe6Pr5kg+jszcIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juniorexz/Codigo/blob/master/Revis%C3%A3olembrar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rS-TJ_M0xzeq",
        "outputId": "0d066eb0-e0ad-4340-f000-3a180c46c336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       preco  vendido  idade_do_modelo   km_por_ano\n",
              "0   30941.02        1               18  35085.22134\n",
              "1   40557.96        1               20  12622.05362\n",
              "2   89627.50        0               12  11440.79806\n",
              "3   95276.14        0                3  43167.32682\n",
              "4  117384.68        1                4  12770.11290"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a5bab2a-f186-457b-a71d-b301340cf9cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preco</th>\n",
              "      <th>vendido</th>\n",
              "      <th>idade_do_modelo</th>\n",
              "      <th>km_por_ano</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30941.02</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>35085.22134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40557.96</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>12622.05362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>89627.50</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11440.79806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95276.14</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>43167.32682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117384.68</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12770.11290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a5bab2a-f186-457b-a71d-b301340cf9cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a5bab2a-f186-457b-a71d-b301340cf9cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a5bab2a-f186-457b-a71d-b301340cf9cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
        "\n",
        "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
        "\n",
        "dados.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# situação horrível de \"azar\" onde as classes estão ordenadas por padrão\n",
        "\n",
        "dados_azar = dados.sort_values(\"vendido\", ascending=True)\n",
        "x_azar = dados_azar[[\"preco\", \"idade_do_modelo\",\"km_por_ano\"]]\n",
        "y_azar = dados_azar[\"vendido\"]\n",
        "dados_azar.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K8HfhohVx43X",
        "outputId": "35a0a731-0790-4fc6-e5bf-a5143a2c0f72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         preco  vendido  idade_do_modelo   km_por_ano\n",
              "4999  74023.29        0               12  24812.80412\n",
              "5322  84843.49        0               13  23095.63834\n",
              "5319  83100.27        0               19  36240.72746\n",
              "5316  87932.13        0               16  32249.56426\n",
              "5315  77937.01        0               15  28414.50704"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33ae2e4c-31a5-42be-a079-07219ccfd435\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preco</th>\n",
              "      <th>vendido</th>\n",
              "      <th>idade_do_modelo</th>\n",
              "      <th>km_por_ano</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>74023.29</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>24812.80412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5322</th>\n",
              "      <td>84843.49</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>23095.63834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5319</th>\n",
              "      <td>83100.27</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>36240.72746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5316</th>\n",
              "      <td>87932.13</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>32249.56426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5315</th>\n",
              "      <td>77937.01</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>28414.50704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ae2e4c-31a5-42be-a079-07219ccfd435')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33ae2e4c-31a5-42be-a079-07219ccfd435 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33ae2e4c-31a5-42be-a079-07219ccfd435');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import numpy as np\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DummyClassifier()\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
        "media = results['test_score'].mean()\n",
        "desvio_padrao = results['test_score'].std()\n",
        "print(\"Accuracy com dummy stratified, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pur5A_3Fx40J",
        "outputId": "bdade1cd-e463-4ddc-dfbb-6a4b7cd42759"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy com dummy stratified, 10 = [58.00, 58.00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
        "media = results['test_score'].mean()\n",
        "desvio_padrao = results['test_score'].std()\n",
        "print(\"Accuracy com cross validation, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmYxQU-Fx4xA",
        "outputId": "1b67dfab-8599-44b4-872e-0c60aab85aa2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy com cross validation, 10 = [73.83, 77.73]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gerando dados aleatórios de modelo de carro para simulação de agrupamento ao usar nosso estimador\n",
        "\n",
        "np.random.seed(SEED)\n",
        "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=10000)\n",
        "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
        "dados.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "78lxz9G4x4t9",
        "outputId": "e21c3433-1b65-4dfe-8ede-614d321673c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       preco  vendido  idade_do_modelo   km_por_ano  modelo\n",
              "0   30941.02        1               18  35085.22134      18\n",
              "1   40557.96        1               20  12622.05362      24\n",
              "2   89627.50        0               12  11440.79806      14\n",
              "3   95276.14        0                3  43167.32682       6\n",
              "4  117384.68        1                4  12770.11290       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f6e22af-780f-468c-bb84-7fea8f780fa9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preco</th>\n",
              "      <th>vendido</th>\n",
              "      <th>idade_do_modelo</th>\n",
              "      <th>km_por_ano</th>\n",
              "      <th>modelo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30941.02</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>35085.22134</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40557.96</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>12622.05362</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>89627.50</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>11440.79806</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95276.14</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>43167.32682</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117384.68</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12770.11290</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f6e22af-780f-468c-bb84-7fea8f780fa9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f6e22af-780f-468c-bb84-7fea8f780fa9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f6e22af-780f-468c-bb84-7fea8f780fa9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imprime_resultados(results):\n",
        "  media = results['test_score'].mean() * 100\n",
        "  desvio = results['test_score'].std() * 100\n",
        "  print(\"Accuracy médio %.2f\" % media)\n",
        "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
      ],
      "metadata": {
        "id": "TD2m9HT8x4q0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupKFold para analisar como o modelo se comporta com novos grupos\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn1JsIkIx4n5",
        "outputId": "b7d40e56-3d21-462a-aa78-8a5d0dd59f3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy médio 75.78\n",
            "Intervalo [73.67, 77.90]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupKFold em um pipeline com StandardScaler e SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "modelo = SVC()\n",
        "\n",
        "pipeline = Pipeline([('transformacao',scaler), ('estimador',modelo)])\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "results = cross_validate(pipeline, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxdRLUIxx4k8",
        "outputId": "9bc1a2f5-d0d3-4d76-86c7-0c1083a51c93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy médio 76.68\n",
            "Intervalo [74.28, 79.08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GroupKFold em um pipeline com StandardScaler e SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "modelo = SVC()\n",
        "\n",
        "pipeline = Pipeline([('transformacao',scaler), ('estimador',modelo)])\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "results = cross_validate(pipeline, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzv51gWK0UF3",
        "outputId": "d416af4b-e742-47fc-8a52-fc9af4e4869c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy médio 76.68\n",
            "Intervalo [74.28, 79.08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglR0NrWx4h2",
        "outputId": "c6d2dbcc-54b7-40da-a2ab-83009d0c08ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O projeto que utilizaremos neste curso é uma continuação do projeto no qual trabalhos no curso de validação cruzada (Cross-validation). Mesmo que você tenha feito o curso, é recomendável utilizar o projeto disponibilizado pelo instrutor, pois foram feitos alguns ajustes para simplificá-lo de acordo com o que será necessário.\n",
        "\n",
        "Se você ainda não fez o curso de validação cruzada, não deixe de verificar se já conhece o conteúdo que, afinal trata-se de um pré-requisito para este curso.\n",
        "\n",
        "Para escrevermos os códigos, usaremos o Google Colab, mas você também pode usar o Jupyter localmente. Na aba \"Upload\", subiremos o arquivo Introdução_a_Machine_Learning_Otimização.ipynb, o mesmo no qual estávamos trabalhando nos cursos anteriores.\n",
        "\n",
        "Então, rodaremos o trecho do código que tenta ler o csv da internet para carregar os dados.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
        "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
        "dados.head()COPIAR CÓDIGO\n",
        "Isso fará com que o seguinte trecho de tabela seja exibido:\n",
        "\n",
        "preco\tvendido\tidade_do_modelo\tkm_por_ano\n",
        "0\t30941.02\t1\t18\t35085.22134\n",
        "1\t40557.96\t1\t20\t12622.05362\n",
        "2\t89627.50\t0\t12\t11440.79806\n",
        "3\t95276.14\t0\t3\t43167.32682\n",
        "4\t117384.68\t1\t4\t12770.11290\n",
        "Cada linha dos dados representa um veículo à venda em um site fictício de vendas de automóveis. A primeira coluna representa o preço de cada veículo; a segunda, se ele foi vendido ou não; a terceira, quantos anos esse modelo tem; e a última, a média de KM esse carro rodou por ano.\n",
        "\n",
        "Temos 3 colunas de informação (nossas features) e 1 coluna de classificação entre sim e não, que é a coluna relativa à venda do carro. Imagine que essa tabela foi gerada baseando-se no status de venda dos carros em um período de 6 meses após entrarem na plataforma, e queremos verificar se um modelo treinado é capaz de aprender isso.\n",
        "\n",
        "Antes de treinarmos o modelo, nós tentamos, de propósito, ordenar os dados de uma maneira que não ajuda nesse treinamento. Nesse caso, eles foram ordenados de acordo com a coluna vendido - primeiro os veículos que não foram vendidos, e depois os que foram vendidos.\n",
        "\n",
        "Isso instigou a necessidade de utilizarmos a validação cruzada.\n",
        "\n",
        "# situação horrível de \"azar\" onde as classes estão ordenadas por padrão\n",
        "\n",
        "dados_azar = dados.sort_values(\"vendido\", ascending=True)\n",
        "x_azar = dados_azar[[\"preco\", \"idade_do_modelo\",\"km_por_ano\"]]\n",
        "y_azar = dados_azar[\"vendido\"]\n",
        "dados_azar.head()COPIAR CÓDIGO\n",
        "preco\tvendido\tidade_do_modelo\tkm_por_ano\n",
        "4999\t74023.29\t0\t12\t24812.80412\n",
        "5322\t84843.49\t0\t13\t23095.63834\n",
        "5319\t83100.27\t0\t19\t36240.72746\n",
        "5316\t87932.13\t0\t16\t32249.56426\n",
        "5315\t77937.01\t0\t15\t28414.50704\n",
        "Com esses dados ordenados, utilizamos o DummyClassifier() para obtermos uma linha de base - ou seja, quão bom bom um modelo é capaz de ser sem que precisássemos fazer muita coisa. O DummyClassifier() é uma boa alternativa nesses casos, principalmente pois, por padrão, ele já é estratificado, utilizando a proporção de 0 e 1 que aparecem nos dados para tentar fazer um julgamento - se aparecem muitos 0, ele vai tentar muitos 0; se aparecem muitos 1, tentará muitos 1.\n",
        "\n",
        "Esse código já foi atualizado para usar cross_validate() (validação cruzada).\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import numpy as np\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DummyClassifier()\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
        "media = results['test_score'].mean()\n",
        "desvio_padrao = results['test_score'].std()\n",
        "print(\"Accuracy com dummy stratified, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))COPIAR CÓDIGO\n",
        "Não se esqueça de adicionar a linha import numpy as np, do contrário o código retornará um erro!\n",
        "\n",
        "Rodando o código, o console retornará \"Accuracy com dummy stratified, 10 = [49.79, 53.45]\" - ou seja, tivemos um intervalo entre aproximadamente 49 e 53.\n",
        "\n",
        "Em seguida, rodamos os mesmos dados (com x_azar, y_azar e cross_validate()) no DecisionTreeClassifier(). Na prática, às vezes utilizamos um DummyClassifier() como linha de base, e às vezes escolhemos um algoritimo simples para essa mesma função. Pode ser preferível rodar os dois, tanto um dummy quanto um algoritmo mais inteligente, pois existem situações em que o algoritmo mais inteligente realmente não se encaixa com aquele modelo.\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
        "media = results['test_score'].mean()\n",
        "desvio_padrao = results['test_score'].std()\n",
        "print(\"Accuracy com cross validation, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))COPIAR CÓDIGO\n",
        "Rodando esse código, retornamos uma taxa bem melhor, entre 73 e 77.\n",
        "\n",
        "Accuracy com cross validation, 10 = [73.83, 77.73]\n",
        "\n",
        "No segundo curso de Machine Learning, uma das formas que trabalhamos foi agrupando os carros por modelos. Como os dados são fictícios, nós criamos juntos o modelo do carro. Utilizamos um código para geração aleatória de informações (mas de maneira replicável) para definirmos a coluna \"modelo\".\n",
        "\n",
        "# gerando dados aleatórios de modelo de carro para simulação de agrupamento ao usar nosso estimador\n",
        "\n",
        "np.random.seed(SEED)\n",
        "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=10000)\n",
        "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
        "dados.head()COPIAR CÓDIGO\n",
        "preco\tvendido\tidade_do_modelo\tkm_por_ano\tmodelo\n",
        "0\t30941.02\t1\t18\t35085.22134\t18\n",
        "1\t40557.96\t1\t20\t12622.05362\t24\n",
        "2\t89627.50\t0\t12\t11440.79806\t14\n",
        "3\t95276.14\t0\t3\t43167.32682\t6\n",
        "4\t117384.68\t1\t4\t12770.11290\t5\n",
        "A coluna \"modelo\" indica qual é o modelo de cada carro - uma variável categoria, na qual os elementos da amostra não possuem relação entre si. O modelo não foi utilizado para tentarmos prever o valor do carro, mas sim para verificar, dado que treinamos o algoritmo em diversos modelos de carro, quão bom ele seria em prever novos modelos de carros.\n",
        "\n",
        "Ou seja, a coluna \"modelo\" não é utilizada como uma feature (no nosso x, que continua sendo x_azar), mas para agrupar os nossos dados.\n",
        "\n",
        "Criamos uma função de resultados:\n",
        "\n",
        "def imprime_resultados(results):\n",
        "  media = results['test_score'].mean() * 100\n",
        "  desvio = results['test_score'].std() * 100\n",
        "  print(\"Accuracy médio %.2f\" % media)\n",
        "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))COPIAR CÓDIGO\n",
        "E rodamos uma validação cruzada que agrupa pelo modelo do carro. Em seguida, rodamos o DecisionTreeClassifier().\n",
        "\n",
        "# GroupKFold para analisar como o modelo se comporta com novos grupos\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)COPIAR CÓDIGO\n",
        "Como resultado, obtemos Accuracy médio 75.78 e Intervalo [73.67, 77.90], o que quer dizer que o algoritmo generalizou bem, assim como se não fosse um modelo novo.\n",
        "\n",
        "Mais tarde, também fizemos classificação com base no SVC (Support Vector Machine).\n",
        "\n",
        "# GroupKFold em um pipeline com StandardScaler e SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "modelo = SVC()\n",
        "\n",
        "pipeline = Pipeline([('transformacao',scaler), ('estimador',modelo)])\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "results = cross_validate(pipeline, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)COPIAR CÓDIGO\n",
        "Nós utilizamos duas vezes o desvio padrão da nossa validação de 10 folds. Como resultado, tivemos:\n",
        "\n",
        "Accuracy médio 76.68\n",
        "\n",
        "Intervalo [74.28, 79.08]\n",
        "\n",
        "No próximo passo, vamos utilizar o DecisionTreeClassifier(). Vamos jogar a célula referente a esse código para baixo e rodá-lo novamente, obtendo a variável modelo, que é justamente o nosso DecisionTreeClassifier().\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "            splitter='best')COPIAR CÓDIGO\n",
        "Agora queremos visualizar essa árvore. Para isso, utilizaremos o Graphviz (import graphviz), uma biblioteca que já utilizamos no passado. Também importaremos o export_graphviz de sklearn.tree.\n",
        "\n",
        "Chamaremos o export_graphviz() para o nosso modelo, definindo que não queremos jogar nenhum arquivo (out_file=None), queremos preencher os retângulos de visualização da árvore de decisão (filled=True), queremos arredondá-los (rounded=True), queremos que os nomes das classes sejam \"não\" e \"sim\" (class_names=[\"não\",\"sim\"], de \"não foi vendido\" e \"sim, foi vendido\") e queremos que os nomes das features sejam os nomes das colunas de x na nossa tabela (feature names = features e features = x_azar.columns).\n",
        "\n",
        "Exportar a visualização devolve dados chamados de dot_data. Finalmente, queremos que o Graphviz utilize dot_data como fonte (graphviz.Source()) e imprima esse gráfico, o que é feito chamando o atributo graph.\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
        "                class_names=[\"não\", \"sim\"], \n",
        "                feature_names =  features)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graphCOPIAR CÓDIGO\n",
        "Para utilizarmos o Graphviz, precisamos primeiro instalá-lo no início do nosso código. Para isso, usaremos !pip install graphviz=0.9. Também usaremos !pip install pydot. Por fim, o Graphviz também precisa ser instalado com !apt-get install graphviz.\n",
        "\n",
        "!pip install graphviz==0.9\n",
        "!pip install pydot\n",
        "\n",
        "!apt-get install grapvizCOPIAR CÓDIGO\n",
        "Da primeira vez que rodarmos esse código, será necessário baixar e instalar tanto os pacotes do Python quanto os pacotes nativos do apt-get, portanto isso levará algum tempo.\n",
        "\n",
        "Agora, quando rodarmos o código para imprimir a visualização da nossa árvore de decisão... teremos um erro dizendo que nossa árvore de decisão ainda não foi treinada.\n",
        "\n",
        "NotFittedError: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\n",
        "\n",
        "Porém, nós fizemos a validação cruzada desse modelo, certo? Na verdade, quando fazemos 10 vezes a validação cruzada, resultamos em 10 modelos diferentes. E qual desses 10 modelos queremos usar? Essa é uma pergunta delicada, e a resposta é que não queremos utilizar nenhum deles. Na validação cruzada, nós treinamos o algoritmo 10 vezes para termos uma estimativa de quão bem esse modelo funcionaria no mundo real. Agora queremos o modelo propriamente dito para utilizarmos na vida real.\n",
        "\n",
        "Portanto, vamos pegar nosso modelo e treiná-lo com x_azar e y_azar.\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "modelo.fit(x_azar, y_azar)\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
        "                class_names=[\"não\", \"sim\"], \n",
        "                feature_names =  features)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graphCOPIAR CÓDIGO\n",
        "Assim, finalmente teremos a visualização da nossa árvore de decisão.\n",
        "\n",
        "visualização da árvore de decisão com profundidade 2\n",
        "\n",
        "Mas repare que essa árvore não é muito profunda, já que possui apenas duas decisões. E se colocássemos três níveis de profundidade? A profundidade máxima é justamente um dos parâmetros que um classifier, como DecisionTreeClassifier(), pode receber. Para testarmos isso, vamos rodar novamente nosso classifier, dessa vez com max_depth=3.\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=3)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)COPIAR CÓDIGO\n",
        "Dessa vez, nosso resultado será:\n",
        "\n",
        "Accuracy médio 78.67\n",
        "\n",
        "Intervalo [76.40, 80.94]\n",
        "\n",
        "Exportando novamente a visualização, teremos uma árvore com até 3 níveis de comparações e a decisão final. Além disso, nosso resultado foi ainda melhor.\n",
        "\n",
        "visualização da árvore de decisão com profundidade 3\n",
        "\n",
        "Será então que, quanto maior o max_depth, melhores serão os resultados? Para testar isso, vamos repetir o processo, dessa vez com max_depth=10.\n",
        "\n",
        "Nosso resultado dessa vez será:\n",
        "\n",
        "Accuracy médio 77.19\n",
        "\n",
        "Intervalo [75.26, 79.13]\n",
        "\n",
        "Ou seja, obtemos valores piores do que os que tínhamos conseguido anteriormente, e a visualização gerada é tão grande que mal cabe na tela do computador.\n",
        "\n",
        "O ponto é: na documentação do SkLearn DecisionTreeClassifier encontramos a informação de que ele tem um parâmetro, chamado max_depth, que pode ser setado para o número que quisermos. Mas como escolhemos esse número, que influencia em quão bem o nosso algorítimo irá rodar?\n",
        "\n",
        "Outros classificadores, como o SVC, também possuem parâmetros que interferem nos resultados do algorítimo. O nosso objetivo nesse curso é entendermos como escolher esses parâmetros para otimizar o nosso estimador. "
      ],
      "metadata": {
        "id": "VksN0iHH1m5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "  print(\"max_depth = %d, media =%.2f\" % (max_depth, results['test_score'].mean() * 100))\n",
        "\n",
        "\n",
        "\n",
        "for i in range (1, 33):\n",
        "      roda_arvore_de_decisao(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5byg-jtVx4ej",
        "outputId": "5b80160c-ef3e-4fc2-f8dc-81e1a2a1385c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth = 1, media =75.78\n",
            "max_depth = 2, media =75.78\n",
            "max_depth = 3, media =78.67\n",
            "max_depth = 4, media =78.63\n",
            "max_depth = 5, media =78.56\n",
            "max_depth = 6, media =78.12\n",
            "max_depth = 7, media =77.96\n",
            "max_depth = 8, media =77.86\n",
            "max_depth = 9, media =77.38\n",
            "max_depth = 10, media =77.19\n",
            "max_depth = 11, media =76.97\n",
            "max_depth = 12, media =76.49\n",
            "max_depth = 13, media =75.81\n",
            "max_depth = 14, media =75.66\n",
            "max_depth = 15, media =75.16\n",
            "max_depth = 16, media =75.11\n",
            "max_depth = 17, media =74.74\n",
            "max_depth = 18, media =74.33\n",
            "max_depth = 19, media =74.34\n",
            "max_depth = 20, media =74.22\n",
            "max_depth = 21, media =73.80\n",
            "max_depth = 22, media =73.81\n",
            "max_depth = 23, media =73.38\n",
            "max_depth = 24, media =73.43\n",
            "max_depth = 25, media =73.14\n",
            "max_depth = 26, media =73.04\n",
            "max_depth = 27, media =72.91\n",
            "max_depth = 28, media =72.66\n",
            "max_depth = 29, media =72.73\n",
            "max_depth = 30, media =72.81\n",
            "max_depth = 31, media =72.86\n",
            "max_depth = 32, media =72.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anteriormente, aprendemos que podemos fornecer parâmetros para nossos estimadores/classificadores (como max_depth) antes de eles serem treinados. Parâmetros que são definidos antes do treino são chamados de hiperparâmetros, e são diferentes de valores internos do modelo que vão sendo alterados de acordo com o que o modelo está aprendendo.\n",
        "\n",
        "Em nosso exemplo, utilizamos a profundidade máxima de uma árvore de decisão padrão do SkLearn. E qual valor escolheremos para ela? Antes de decidirmos, vamos testar diversos valores e prestar atenção no que acontece. Para isso, rodaremos o DecisionTreeClassifier() várias vezes, de 1 até 32.\n",
        "\n",
        "Criaremos uma função roda_arvore_de_decisao() que roda a árvore de decisão para uma profundidade específica. Essa função será usada como parâmetro de max_depth.\n",
        "\n",
        "Com isso, se chamarmos a árvore de decisão com 10, essa árvore será chamada até o máximo 10, e assim sucessivamente. Portanto, podemos fazer um for i in range() passando o intervalo 1,33 - ou seja, de 1 até 32, excluindo 33, e passar i como max_depth da função.\n",
        "\n",
        "Também precisaremos mudar a função que exibe os resultados, pois imprime_resultados() não trará uma resposta facilmente legível e que ainda contém informações desnecessárias.\n",
        "\n",
        "Nesse instante, vamos imprimir somente o tamanho do max_depth e a média do test_score:\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "  print(\"max_depth = %d, media =%.2f\" % (max_depth, results['test_score'].mean() * 100))\n",
        "\n",
        "\n",
        "\n",
        "for i in range (1, 33):\n",
        "      roda_arvore_de_decisao(i)COPIAR CÓDIGO\n",
        "Como resultado, teremos:\n",
        "\n",
        "max_depth = 1, media =75.78\n",
        "\n",
        "max_depth = 2, media =75.78\n",
        "\n",
        "max_depth = 3, media =78.67\n",
        "\n",
        "max_depth = 4, media =78.63\n",
        "\n",
        "max_depth = 5, media =78.56\n",
        "\n",
        "max_depth = 6, media =78.12\n",
        "\n",
        "max_depth = 7, media =77.96 max_depth = 8, media =77.86\n",
        "\n",
        "max_depth = 9, media =77.38\n",
        "\n",
        "max_depth = 10, media =77.19\n",
        "\n",
        "max_depth = 11, media =76.97\n",
        "\n",
        "max_depth = 12, media =76.49\n",
        "\n",
        "max_depth = 13, media =75.81\n",
        "\n",
        "(...)\n",
        "\n",
        "O que esperaríamos é que, quanto maior fosse a profundidade da árvore, mais decisões ela precisaria tomar e mais perfeito seria o seu treinamento em relação aos nossos testes. Porém, a partir de max_depth=3, que possui uma média 78.67, temos uma queda constante até max_depth = 32, que possui a média mais baixa, 72.52.\n",
        "\n",
        "Isso acontece porque, quando treinamos a nossa árvore, ela aprende e cria as suas ramificações. Com profundidades muito grandes, a árvore se torna tão perfeita para os dados de treino que falha nos dados de teste - quase como se ela tivesse memorizado o teste.\n",
        "\n",
        "Vamos verificar se é isso mesmo que está acontecendo?"
      ],
      "metadata": {
        "id": "zynDNVxL2JtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Pause\n",
        "Unmute\n",
        "Current Time 10:13\n",
        "/\n",
        "Duration 10:22\n",
        "1.25xPlayback Rate\n",
        "Open quality selector menuPicture-in-Picture\n",
        "Open Theater Mode\n",
        "Fullscreen\n",
        "Transcrição\n",
        "Além de imprimirmos o valor do teste, queremos imprimir também o valor do treino. Para isso, atribuiremos True para return_train_score, e passaremos \"Arvore max_depth = %d, treino = %.2f, teste = %.2f,\" % (max_depth, results['train_score'].mean() * 100, results['test_score'].mean() * 100) para o método print().\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  print(\"Arvore max_depth = %d, treino = %.2f, teste = %.2f,\" % (max_depth, results['train_score'].mean() * 100, results['test_score'].mean() * 100))\n",
        "\n",
        "\n",
        "\n",
        "for i in range (1, 33):\n",
        "      roda_arvore_de_decisao(i)COPIAR CÓDIGO\n",
        "Assim como esperávamos, os treinos serão cada vez melhores, mas rapidamente cairão com os dados de teste.\n",
        "\n",
        "Arvore max_depth = 1, treino = 75.79, teste = 75.78,\n",
        "\n",
        "Arvore max_depth = 2, treino = 75.79, teste = 75.78,\n",
        "\n",
        "Arvore max_depth = 3, treino = 78.75, teste = 78.67,\n",
        "\n",
        "Arvore max_depth = 4, treino = 78.79, teste = 78.63,\n",
        "\n",
        "Arvore max_depth = 5, treino = 78.94, teste = 78.56,\n",
        "\n",
        "(...)\n",
        "\n",
        "Arvore max_depth = 28, treino = 96.75, teste = 72.66,\n",
        "\n",
        "Arvore max_depth = 29, treino = 97.10, teste = 72.73,\n",
        "\n",
        "Arvore max_depth = 30, treino = 97.43, teste = 72.81,\n",
        "\n",
        "Arvore max_depth = 31, treino = 97.80, teste = 72.86,\n",
        "\n",
        "Arvore max_depth = 32, treino = 98.10, teste = 72.52\n",
        "\n",
        "Qqueremos visualizar esses resultados de maneira mais inteligível. Para isso, começaremos extraindo as variável train_score e test_score:\n",
        "\n",
        "train_score = results['train_score'].mean() * 100\n",
        "test_score = results['test_score'].mean() * 100COPIAR CÓDIGO\n",
        "Em seguida, criaremos uma variável tabela recebendo um array de três valores: max_depth, train_score e test_score, e retornaremos essa tabela:\n",
        "\n",
        "tabela = [max_depth, train_score, test_score]\n",
        "return tabelaCOPIAR CÓDIGO\n",
        "Assim, a função roda_arvoce_de_decisao() está nos devolvendo uma tabela. Existem várias maneiras de agruparmos esses dados. Nesse caso, usaremos uma feature do Python chamada list comprehension.\n",
        "\n",
        "Queremos rodar o código de roda_arvore_de_decisao() para cada um dos i, nos devolvendo uma lista que contémtabela e atribuindo-a a uma variável resultados. Para conseguirmos trabalhar melhor com esses dados, vamos transformá-la em um dataframe do Pandas com pd.DataFrame(), passando resultados e os nomes das colunas max_depth, train e test, e vamos imprimir resultados com .head().\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "  print(\"Arvore max_depth = %d, treino = %.2f, teste = %.2f\" % (max_depth, results['train_score'].mean() * 100, results['test_score'].mean() * 100))\n",
        "  tabela = [max_depth, train_score, test_score]\n",
        "  return tabela\n",
        "\n",
        "resultados = [roda_arvore_de_decisao(i) for i in range (1, 33)]\n",
        "resultados = pd.DataFrame(resultados, columns = [\"max_depth\", \"train\", \"test\"])\n",
        "resultados.head()\n",
        "COPIAR CÓDIGO\n",
        "Como resultado, o console nos retornará a tabela abaixo:\n",
        "\n",
        "max_depth\ttrain\ttest\n",
        "0\t1\t75.791169\t75.784219\n",
        "1\t2\t75.791169\t75.784219\n",
        "2\t3\t78.750993\t78.672633\n",
        "3\t4\t78.787628\t78.632803\n",
        "4\t5\t78.941007\t78.555912\n",
        "Agora que temos uma tabela do Pandas, podemos transformá-la em um gráfico. Para isso, importaremos a biblioteca searbon como sns, e escreveremos um plot de linha (lineplot()) cujos dados são os resultados (data = resultados).\n",
        "\n",
        "No eixo x, queremos a profundidade (x = \"max_depth\"), e no eixo y queremos as médias do treino (y = \"train\"). Repetindo esse processo, dessa vez mudando o eixo y para as médias do teste (y = \"test\"), teremos os dois gráficos sendo plotados um sobre o outro, o que nos permitirá enxergar bem esses dados.\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.lineplot(x = \"max_depth\", y = \"train\", data = resultados)\n",
        "sns.lineplot(x = \"max_depth\", y = \"test\", data = resultados)COPIAR CÓDIGO\n",
        "Como a versão padrão do seaborn no Google Colab é antiga e não possui o lineplot(), será necessário, no início da execução, instalarmos a versão 0.9.0, que contém essa função.\n",
        "\n",
        "!pip install seaborn==0.9.0COPIAR CÓDIGO\n",
        "Ao fazermos isso, também será necessário reiniciar a máquina virtual (\"Runtime > Restart Runtime\") para que a versão correta seja carregada. Executando nosso código, o gráfico será gerado na tela.\n",
        "\n",
        "\n",
        "\n",
        "Nele, podemos analisar que conforme aumentamos o max_depth, a média do treino vai ficando cada vez melhor, chegando a quase 100%. Porém, em determinado momento, o algoritmo começa a ficar tão exato para o modelo que deixa de ser adequado para os testes, com a média sendo cada vez menor.\n",
        "\n",
        "Esse tipo de cenário é chamado de overfitting.\n",
        "\n",
        "Antes de prosseguirmos, vamos adicionar legendas no gráfico para que ele fique ainda mais legível. Para isso, importaremos matplotlib.pyplot as plt e usaremos plt.legend() para passar nossas legendas Treino e Teste.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.lineplot(x = \"max_depth\", y = \"train\", data = resultados)\n",
        "sns.lineplot(x = \"max_depth\", y = \"test\", data = resultados)\n",
        "plt.legend([\"Treino\", \"Teste\"])COPIAR CÓDIGO\n",
        "Agora que varremos todo esse espaço de possibilidades, podemos ordenar os resultados a partir da qualidade do teste (resultados.sort_values(\"test\")) de maneira decrescente (ascending=False), utilizando .head() para mostrar somente os cinco primeiros.\n",
        "\n",
        "resultados.sort_values(\"test\", ascending=False).head()COPIAR CÓDIGO\n",
        "Podemos perceber as melhores árvores tiveram max_depth = 3, max_depth = 4 ou max_depth = 5. Portanto, usaríamos, por exemplo, max_depth = 3.\n",
        "\n",
        "max_depth\ttrain\ttest\n",
        "3\t78.750993\t78.672633\n",
        "4\t78.787628\t78.632803\n",
        "5\t78.941007\t78.555912\n",
        "6\t79.170115\t78.123266\n",
        "7\t79.496806\t77.963185\n",
        "Veremos mais variações de parâmetros e como tomar essa decisão nas próximas aulas. Até o momento, devemos entender max_depth é um exemplo de parâmetro de um algoritmo como a árvore decisão. Além disso, é perigoso varrermos demais os dados do treino e, consequentemente, prejudicarmos os resultados do teste.Recapitulando: nós estudamos um parâmetro da árvore de decisão, chamado \"profundidade máxima\", testando-o com diversos valores dentro de um intervalo discreto. Com isso, descobrimos que a média da accuracy do nosso algoritmo teve uma fase de crescimento, mas rapidamente caiu conforme os valores foram aumentando.\n",
        "\n",
        "É impossível dizer que essa média sempre aumentaria ou diminuiria de acordo com os valores atribuídos aos parâmetros, já que isso depende muito do tipo de parâmetro e dos dados que estamos utilizando. De maneira a contornar isso, nossa alternativa foi realizar os testes com uma grande quantidade de valores.\n",
        "\n",
        "Apesar da quantidade de dados, nosso algoritmo foi razoavelmente rápido. Porém, o processo de treinar com validação cruzada utilizando grupos pode demorar mais tempo - por exemplo, 5 minutos para treinar e testar 1 valor de um parâmetro. Nesse caso, rodar o código 64 vezes levaria 5 horas e meia, e só então saberíamos qual desses valores foi melhor. E se esse processo levasse meia hora por cada valor?\n",
        "\n",
        "Existem opções, como distribuir os processos, rodá-los em paralelo ou na nuvem, mas o que queremos no momento é entender o que é o espaço de parâmetro e como otimizar esses espaços - não só o algoritmo, como também o tempo de busca dos melhores parâmetros nesse espaço.\n",
        "\n",
        "Uma das estratégias possíveis é pegar um parâmetro e varrer os dados com ele. Essa técnica tem suas vantagens e desvantagens, e é com ela que trabalharemos agora.\n",
        "Definir sobre max_depth;\n",
        "Definir sobre a árvore de decisão ( DecisionTreeClassifier);\n",
        "Mostrar gráficos com o seaborn;\n",
        "Mostrar gráficos com matplotlib;\n",
        "Definir hiperparâmetros.\n"
      ],
      "metadata": {
        "id": "o10-cbxX5aHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anteriormente, aprendemos que é possível explorar o espaço de um parâmetro do nosso classificador, como o max_depth. Se testássemos, por exemplo, 64 valores para esse parâmetro, teríamos alguns problemas e necessidades. Felizmente, esse não é o nosso objetivo nesse instante, e quando for nós encontraremos outras estratégias mais simples.\n",
        "\n",
        "O importante agora é notar que, como consta na documentação do DecisionTreeClassifier, esse algorítimo possui diversos outros parâmetros - dentre os quais nem todos são hiperparâmetros.\n",
        "\n",
        "Um hiperparãmetro é um parâmetro que é setado previamente e que define a regra de criação da nossa árvore de decisão, como o próprio max_depth. Outro exemplo seria min_samples_leaf, que é número mínimo de elementos (samples) em uma folha.\n",
        "\n",
        "As folhas são os últimos nós de uma árvore de decisão, a partir dos quais não ocorrem mais decisões. Um exemplo de uma árvore \"perfeita\" seria aquela em que todas as suas folhas contivessem somente um elemento - ou seja, na qual cada elemento tivesse uma classificação específica.\n",
        "\n",
        "Mas não queremos que o número de samples seja muito baixo, pois isso faria com que o nosso algoritmo ficasse muito específico para o treino, não conseguindo generalizar tão bem para os testes. É para isso que serve o hiperparâmetro min_samples_leaf.\n",
        "\n",
        "Nosso objetivo agora é explorarmos ambos os espaços de parâmetros, max_depth e min_samples_leaf, com diversos valores discretos.\n",
        "\n",
        "Poderíamos começar testando max_depth = 1 e min_samples_leaf = 1, depois max_depth = 1 e min_samples_leaf = 2, e assim sucessivamente até termos explorado todas as combinações de parâmetros. Isso resulta em 4096 testes (64 possibilidades do primeiro parâmetro multiplicadas por 64 possibilidades do segundo). Se cada um desses testes levasse 5 minutos, levaríamos 341 horas - aproximadamente 14 dias rodando o algoritmo. Complicado, não? E se tivéssemos ainda mais parâmetros - por exemplo, 10?\n",
        "\n",
        "Aprenderemos mais sobre isso nas próximas lições.\n",
        "Dessa vez, ao invés de rodarmos nossa árvore de decisão para um único parâmetro, a rodaremos para dois. Para isso, criaremos uma cópia do código de roda_arvore_de_decisao(), dessa vez passando max_depth e min_samples_leaf.\n",
        "\n",
        "Em DecisionTreeClassifier(), adicionaremos o trecho min_samples_leaf = min_samples_leaf para passarmos o parâmetro para nosso modelo. Também precisamos incluir min_samples_leaf = %d na função print(), e min_samples_leaf na tabela e no resultado das nossas colunas.\n",
        "\n",
        "Como queremos rodar dois valores por vez, não usaremos list comprehension, pois os resultados não seriam tão facilmente legíveis. Vamos começar passando resultados = [] e, depois, criaremos um for max_depth in range(1,33) que culmina em for min_samples_leaf in range(1,33).\n",
        "\n",
        "Em seguida, tabela deve receber a função roda_arvore_de_decisao com max_depth e min_samples_leaf. Essa tabela será adicionada nos resultados com resultados.append(tabela).\n",
        "\n",
        "Como esse código está muito solto, vamos agrupá-lo em uma função busca() que devolve resultados. Por mim, definiremos resultados = busca() e chamaremos busca.head() para imprimir os cinco primeiro elementos desses resultados.\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "  print(\"Arvore max_depth = %d, min_samples_leaf = %d, treino = %.2f, teste = %.2f\" % (max_depth, min_samples_leaf, train_score, test_score))\n",
        "  tabela = [max_depth, min_samples_leaf, train_score, test_score]\n",
        "  return tabela\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    for min_samples_leaf in range(1,33):\n",
        "        tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
        "        resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Rodar esse código todo vai levar muito tempo. Como não queremos isso, ao invés de testarmos todo o espaço do parâmetro min_samples_leaf, rodaremos apenas uma lista com alguns valores:\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:COPIAR CÓDIGO\n",
        "Dessa forma, teremos apenas 128 pares de hiperparâmetros testados. Para analisarmos os resultados, vamos imprimir na tela a tabela dos melhores resultados:\n",
        "\n",
        "resultados.sort_values(\"test\", ascending=False).head()COPIAR CÓDIGO\n",
        "Pelo que podemos perceber, os cinco melhores atingiram aproximadamente 78% no teste, todos com max_depth = 4. Já o min_samples_leaf parece não ter influenciado o resultado quando max_depth = 4.\n",
        "\n",
        "max_depth\tmin_samples_leaf\ttrain\ttest\n",
        "4\t256\t78.750993\t78.672633\n",
        "4\t32\t78.750993\t78.672633\n",
        "4\t128\t78.750993\t78.672633\n",
        "4\t64\t78.750993\t78.672633\n",
        "3\t32\t78.750993\t78.672633\n",
        "Agora que temos dois hiperparâmetros e estamos em um espaço de duas dimensões, vamos explorar ainda mais esses dados."
      ],
      "metadata": {
        "id": "N9EpScRZ7YTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste momento, temos uma tabela que indica a situação de dois parâmetros e quão bem um modelo foi no treino e no teste. Nossa dúvida é: como estão se comportando os resultados de treino e de teste em função dos valores de cada parâmetro?\n",
        "\n",
        "max_depth\tmin_samples_leaf\ttrain\ttest\n",
        "4\t256\t78.750993\t78.672633\n",
        "4\t32\t78.750993\t78.672633\n",
        "4\t128\t78.750993\t78.672633\n",
        "4\t64\t78.750993\t78.672633\n",
        "3\t32\t78.750993\t78.672633\n",
        "Existe uma dificuldade de apreendermos exatamente o que está acontecendo nesses dados: primeiro, porque a tabela é enorme e estamos mostrando apenas os cinco melhores resultados; e também porque estamos omitindo diversos valores possíveis do nosso teste. Será que o resultado seria melhor se tivéssemos escolhido, por exemplo, min_samples_leaf = 57? E min_samples_leaf = 300?\n",
        "\n",
        "Testar todas as possibilidades consome muito processamento. Uma das abordagens possíveis - claramente a mais complexa -, seria paralelizar esse processamento, distribuindo-o em várias máquinas.\n",
        "\n",
        "Outra maneira de tentarmos visualizar se existem espaços de parâmetros melhores para o nosso algoritmo é procurarmos uma relação entre o resultado de teste e esses parâmetros por meio de uma análise de correlação. O próprio Pandas nos disponibiliza esse tipo de análise estatística tradicional, bastando escrevermos resultados.corr().\n",
        "\n",
        "max_depth\tmin_samples_leaf\ttrain\ttest\n",
        "max_depth\t1.000000\t0.000000\t0.681408\t-0.522835\n",
        "min_samples_leaf\t0.000000\t1.000000\t-0.453825\t0.528330\n",
        "train\t0.681408\t-0.453825\t1.000000\t-0.762534\n",
        "test\t-0.522835\t0.528330\t-0.762534\t1.000000\n",
        "Quanto mais alto o valor, mais correlacionados estão os elementos na comparação. Por exemplo, quanto maior o max_depth, maior será o max_depth. Essa é uma conclusão bastante óbvia, afinal o max_depth é ele mesmo, mas que nos ajuda a entender o que está acontecendo. Além disso, repare resultados positivos (maiores que 0) representam uma correlação positiva, e negativos uma correlação negativa.\n",
        "\n",
        "Outras conclusões que podemos tirar a partir desses resultados:\n",
        "\n",
        "quando max_depth cresce, o treino parece crescer também\n",
        "quando min_samples_leaf cresce, o treino cai\n",
        "quando max_depth sobe, o teste cai\n",
        "quando min_samples_leaf sobe, o teste sobe\n",
        "Note que essa não é uma prova de causalidade, mas um teste de correlação.\n",
        "\n",
        "Uma técnica comum para visualizarmos essa correlação é plotar esses resultados em um gráfico. Primeiramente, atribuiremos essa correlação a uma variável corr. Em seguida, com o seaborn, impriremos a correlação em um mapa de calor (sns.heatmap(corr)).\n",
        "\n",
        "mapa de calor correlacionando `max_depth`, `min_samples_leaf`, `train` e `test` \n",
        "\n",
        "No nosso exemplo, os espaços mais próximos da cor vinho têm uma correlação muito alta, como fica claro nos quadrados da diagonal. Em contrapartida, quanto mais próximos do azul marinho, menor é essa correlação.\n",
        "\n",
        "Existem outras maneiras de visualizarmos essa correlação. Dessa vez, usaremos outro tipo de comparação desses valores: uma matriz que mostra os pontos soltos (scatter_matrix()).\n",
        "\n",
        "Nela, passaremos os resultados, acompanhados de figsize = (14, 8) (para que os gráficos fiquem um pouco maiores e mais fáceis de serem analisados) e alpha = 0.3 (para ajustarmos a transparência dos pontos plotados).\n",
        "\n",
        "pd.scatter_matrix(resultados, figsize = (14, 8), alpha = 0.3)COPIAR CÓDIGO\n",
        "Dessa forma, serão gerados os seguintes gráficos:\n",
        "\n",
        "\n",
        "\n",
        "Na diagonal, são exibidos os histogramas dos valores. Por exemplo, para train, tivemos diversos resultados na faixa de 79%, e no test tivemos diversos valores na faixa de 78%.\n",
        "\n",
        "Já os gráficos que não compõem a diagonal são equivalentes à nossa correlação - à medida em que max_depth aumenta, o resultado de test cai e o resultado de train sobe, entre outras correlações.\n",
        "\n",
        "Outra visualização possível no Seaborn é o pairplot(), que plota os resultados pareados, de maneira muito parecida com nossa scatter_matrix.\n",
        "\n",
        "sns.pairplot(resultados)COPIAR CÓDIGO\n",
        "Na diagonal, teremos novamente os histogramas dos valores. Os outros gráficos fazem os relacionamentos de um parâmetro em função do outro, e novamente podemos analisar que, enquanto max_depth aumenta, o test cai.\n",
        "\n",
        "\n",
        "\n",
        "No gráfico do canto inferior esquerdo, temos 4 linhas que provavelmente representam cada valor de min_samples_leaf. Entretanto, ao menos nesse gráfico, é impossível visualizarmos qual valor cada linha representa.\n",
        "\n",
        "Por último, geraremos outro gráfico que consta na própria documentação do seaborn correlations, a matriz de correlação diagonal (diagonal correlation matrix). Para isso, copiaremos o código que consta nessa documentação, apenas removendo os trechos em que os dados são gerados e atribuídos à uma variável corr.\n",
        "\n",
        "from string import ascii_letters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})COPIAR CÓDIGO\n",
        "Nosso resultado é o seguinte gráfico:\n",
        "\n",
        "\n",
        "\n",
        "Repare que somente os dados que nos interessam (ou seja, aqueles que não são equivalentes) são plotados com cores na matriz. Nela, percebemos que parece existir uma correlação muito forte entre test e min_samples_leaf - quanto maior o min_samples_leaf, maior a qualidade do test.\n",
        "\n",
        "Com esses dados em mãos, podemos então testar outros valores. Como obtivemos resultados melhores com 128 e 256, vamos mantê-los, adicionando 192 e 512.\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    for min_samples_leaf in [128, 192, 256, 512]:\n",
        "        tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
        "        resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Isso não garante que iremos encontrar o melhor valor possível para o nosso parâmetro, mas é uma maneira de explorarmos as possibilidades e resultados.\n",
        "\n",
        "Após executarmos esse código, vamos rodar novamente corr = resultados.corr() e o código que gera a nossa matriz.\n",
        "\n",
        "\n",
        "\n",
        "Dessa vez, o resultado é uma correlação negativa entre min_samples_leaf e test.\n",
        "\n",
        "Com resultados.sort_values(\"test\", ascending=False).head(), analisaremos outra vez quais foram os cinco melhores resultados desse teste:\n",
        "\n",
        "max_depth\tmin_samples_leaf\ttrain\ttest\n",
        "4\t192\t78.750993\t78.672633\n",
        "3\t128\t78.750993\t78.672633\n",
        "3\t192\t78.750993\t78.672633\n",
        "3\t256\t78.750993\t78.672633\n",
        "4\t256\t78.750993\t78.672633\n",
        "Essa é uma maneira de tentarmos encontrar os valores que mais otimizam o nosso estimador, com o menor índice de erro e o maior nível de qualidade. Fizemos isso com dois parâmetros, mas é possível trabalhar com um número ainda maior!\n",
        "Definir os elementos mínimos em uma árvore de decisão;\n",
        "Utilizar o min_samples_leaf para treino;\n",
        "O que é corr do pandas;Nas aulas anteriores, exploramos um espaço de 2 dimensões, atrelado a 2 parâmetros. Mesmo assim, não exploramos todo o espaço de parâmetros, e mesmo que tenhamos encontrado valores que parecem razoáveis, não temos garantia de que são os melhores possíveis.\n",
        "\n",
        "Na documentação do DecisionTreeClassifier, encontramos diversos outros parâmetros - e vários deles são hiperparâmetros.\n",
        "\n",
        "Dessa vez, vamos trabalharemos com min_samples_split. Antes, estávamos explorando o mínimo de samples em um nó final (a nossa \"folha\"), e agora exploraremos o mínimo de \"quebras\" (splits) que podemos ter no meio da árvore.\n",
        "\n",
        "Para isso, na nossa função busca(), precisaremos criar mais um for, novamente com valores fixos - nesse caso, 32, 64, 128 e 256. Além disso, min_samples_split deve ser adicionado:\n",
        "\n",
        "como parâmetro da função roda_arvore_de_decisao()\n",
        "como parâmetro de DecisionTreeClassifier().\n",
        "como um dos valores de tabela\n",
        "como uma das colunas de DataFrame()\n",
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "\n",
        "  tabela = [max_depth, min_samples_leaf, min_samples_split, train_score, test_score]\n",
        "  return tabela\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:\n",
        "        for min_samples_split in [32, 64, 128, 256]:\n",
        "          tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split)\n",
        "          resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\", \"min_samples_split\", \"train\",\"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Repare que removemos o trecho no qual os resultados eram imprimidos na tela. Isso porque, além de aumentar o tempo de execução do nosso código - que já é 4 vezes maior que quando tínhamos apenas 2 parâmetros -, a lista de resultados não nos trazia nenhuma informação relevante, já que era praticamente ilegível, servindo apenas para acompanharmos o debug.\n",
        "\n",
        "O resultado na tela é a seguinte tabela:\n",
        "\n",
        "max_depth\tmin_samples_leaf\tmin_samples_split\ttrain\ttest\n",
        "1\t32\t32\t75.791169\t75.784219\n",
        "1\t32\t64\t75.791169\t75.784219\n",
        "1\t32\t128\t75.791169\t75.784219\n",
        "1\t32\t256\t75.791169\t75.784219\n",
        "1\t64\t32\t75.791169\t75.784219\n",
        "Em seguida, assim como fizemos anteriormente, vamos analisar a correlação e imprimir o gráfico de matriz de correlação diagonal.\n",
        "\n",
        "\n",
        "\n",
        "Com base nesse gráfico e na análise dos 5 melhores resultados do teste, poderíamos tomar uma decisão entre continuar explorando esse espaço de parâmetros ou não.\n",
        "\n",
        "Outro fator que pode ser analisado é o tempo que a máquina virtual leva para treinar o algoritmo. O próprio cross_validate() tem, entre os seus resultados, a cronometragem do tempo. Portanto, basta extrairmos as variáveis referentes ao tempo e imprimirmos na tabela.\n",
        "\n",
        "Usaremos fit_time = results['fit_time'].mean() e score_time = results['score_time'].mean() para extrairmos a média de tempo do treino e do teste. Também precisaremos passar fit_time e score_time como parâmetros de tabela e como colunas de DataFrame().\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  fit_time = results['fit_time'].mean()\n",
        "  score_time = results['score_time'].mean()\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "\n",
        "  tabela = [max_depth, min_samples_leaf, min_samples_split, train_score, test_score, fit_time, score_time]\n",
        "  return tabela\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:\n",
        "        for min_samples_split in [32, 64, 128, 256]:\n",
        "          tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split)\n",
        "          resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\", \"min_samples_split\", \"train\",\"test\", \"fit_time\", \"score_time\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Rodando esse código, iremos testar 512 combinações diferentes de hiperparâmetros no nosso cross_validate(), que são 10 tentativas de treino e teste. Portanto, são 5120 splits de treino/teste no nosso modelo, e por isso a execução demora algum tempo.\n",
        "\n",
        "Após a execução, geraremos novamente a tabela com os 5 melhores resultados e o gráfico plotando a correlação dos dados:\n",
        "\n",
        "max_depth\tmin_samples_leaf\tmin_samples_split\ttrain\ttest\tfit_time\tscore_time\n",
        "4\t256\t256\t78.750993\t78.672633\t0.012417\t0.001120\n",
        "4\t32\t32\t78.750993\t78.672633\t0.012679\t0.001225\n",
        "3\t32\t128\t78.750993\t78.672633\t0.010398\t0.000980\n",
        "3\t32\t256\t78.750993\t78.672633\t0.011309\t0.001135\n",
        "3\t64\t32\t78.750993\t78.672633\t0.010484\t0.001216\n",
        "\n",
        "\n",
        "Repare que existe uma pequena diferença entre os tempos de treino e os treinos de teste. Nesse caso, nosso treino é tão rápido que essas diferenças são insignificantes. Porém, se tivéssemos um algoritmo que demora 30 minutos para fazer o treinamento e no qual o tempo de teste fosse muito alto, talvez valesse a pena escolhermos os valores com base nesses resultados.\n",
        "\n",
        "Além dos 3 parâmetros que analisamos até agora, o DecisionTreeClassifier possui vários outros, a exemplo do critério de análise da árvore (como e/ou quando quebrar). Esse parâmetro pode receber dois diferentes valores, como gini ou entropy.\n",
        "\n",
        "Os parâmetros de um algoritmo estimador não precisam ser discretos como os que estudados até o momento. Por exemplo, existem casos em que trabalhamos com escala logarítmica ou exponencial, e é mais interessante explorar valores mais altos ou mais baixos. Ou seja, existem vários tipos de espaços de parâmetros que podem ser explorados.\n",
        "\n",
        "Agora que aprendemos a trabalhar com 3 parâmetros, lembre-se que é possível utilizar 4, 5 ou dezenas de parâmetros diferentes. Na prática, não há como explorar todas as possibilidades, portanto a ideia é explorarmos somente uma seleção delas - assim como estamos fazendo nesse curso. Com todo o esforço que isso demanda, seria ideal se tivéssemos uma biblioteca que já fizesse esse processo de otimização do nosso modelo.\n",
        "\n",
        "Felizmente, o SKLearn tem uma maneira de buscar a otimização de parâmetros em um grid., e aprenderemos mais sobre ela a seguir.Agora que já aprendemos a importância de uma busca em grid pelos parâmetros que maximizam a métrica que estamos utilizando no nosso sistema, queremos utilizar uma ferramenta que nos ajude nesse processo.\n",
        "\n",
        "O próprio SKLearn possui o GridSearchCV (grid search cross validation), que faz justamente essa busca de hiperparâmetros com validação cruzada.\n",
        "\n",
        "Para isso, importaremos o GridSearchCV do sklearn.model_selection. Em seguida, determinaremos o SEED como 301 (mantendo o mesmo seed padrão) e definiremos o nosso espaco_de_parametros.\n",
        "\n",
        "Ele deve conter diversas dimensões:\n",
        "\n",
        "max_depth com os valores 3 e 5\n",
        "min_samples_split com os valores 32, 64 e 128\n",
        "min_samples_leaf também com os valores 32, 64 e 128\n",
        "criterion com os valores gini e entropy (que são strings)\n",
        "Ou seja, estaremos explorando 4 dimensões diferentes que resultam em 36 combinações. Nossa busca será um GridSearchCV(), passando DecisionTreeClassifier(), espaco_de_parametros e o cross validation com 10 splits (cv = GroupKFold(n_split = 10)).\n",
        "\n",
        "O GridSearchCV() vai funcionar como um modelo. Portanto, podemos fazer busca.fit(), que irá rodar o cross validation dentro dele. Portanto, passaremos os parâmetros x_azar e y_azar, e os grupos (groups = dados.modelo).\n",
        "\n",
        "Depois da busca, passaremos para o nosso pd.DataFrame() o cv_results_, um dicionário do GridSearchCV que pode ser importado em dataframe do Pandas. Por mim, escreveremos resultados.head() para recebermos os 5 melhores resultados.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = GroupKFold(n_splits = 10))\n",
        "\n",
        "busca.fit(x_azar, y_azar,groups = dados.modelo)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Executando esse código, o resultado é a tabela abaixo:\n",
        "\n",
        "mean_fit_time\tmean_score_time\tmean_test_score\tmean_train_score\tparam_criterion\tparam_max_depth\tparam_min_samples_leaf\tparam_min_samples_split\tparams\trank_test_score\t...\tsplit7_test_score\tsplit7_train_score\tsplit8_test_score\tsplit8_train_score\tsplit9_test_score\tsplit9_train_score\tstd_fit_time\tstd_score_time\tstd_test_score\tstd_train_score\n",
        "0.011356\t0.001306\t0.7868\t0.78751\tgini\t3\t32\t32\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.781818\t0.788124\t0.77551\t0.788803\t0.790262\t0.786834\t0.002153\t0.000076\t0.011338\t0.001303\n",
        "0.010387\t0.001217\t0.7868\t0.78751\tgini\t3\t32\t64\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.781818\t0.788124\t0.77551\t0.788803\t0.790262\t0.786834\t0.000241\t0.000075\t0.011338\t0.001303\n",
        "0.010206\t0.001158\t0.7868\t0.78751\tgini\t3\t32\t128\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.781818\t0.788124\t0.77551\t0.788803\t0.790262\t0.786834\t0.000115\t0.000055\t0.011338\t0.001303\n",
        "0.010272\t0.001195\t0.7868\t0.78751\tgini\t3\t64\t32\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.781818\t0.788124\t0.77551\t0.788803\t0.790262\t0.786834\t0.000179\t0.000057\t0.011338\t0.001303\n",
        "0.010216\t0.001215\t0.7868\t0.78751\tgini\t3\t64\t64\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.781818\t0.788124\t0.77551\t0.788803\t0.790262\t0.786834\t0.000217\t0.000111\t0.011338\t0.001303\n",
        "Essa tabela nos mostra diversas informações, como a média do tempo de treino, a média do tempo de teste, a acurácia do teste e do treino e o ranking delas, quais foram cada um dos parâmetros utilizados, entre outras.\n",
        "\n",
        "Com busca.best_params_, podemos imprimir na tela os melhores parâmetros; e com busca.best_score_ * 100, o melhor resultado em porcentagem:\n",
        "\n",
        "print(busca.best_params_)\n",
        "print(busca.best_score_ * 100)COPIAR CÓDIGO\n",
        "{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 32, 'min_samples_split': 32}\n",
        "\n",
        "78.68%\n",
        "\n",
        "Se quisermos o melhor estimador em si, podemos pegá-lo com busca.best_estimator_:\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=32, min_samples_split=32,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "            splitter='best')COPIAR CÓDIGO\n",
        "Se quiséssemos, também poderíamos rodar a correlação e montar um gráfico em cima desses dados.\n",
        "\n",
        "Dado esse resultado, quão bem ele se sairia no mundo real? No curso anterior, aprendemos que, depois que treinamos o estimador com cross validation, podemos rodar um fit para obtermos o modelo que utilizaremos no mundo real. Como já temos esse modelo, podemos tentar predizer a sua acurácia com melhor.predict(x_azar), que atribuiremos a uma variável predicoes.\n",
        "\n",
        "Em seguida, criaremos uma variável accuracy recebendo accuracy_score(predicoes, y_azar) * 100. Lembre-se de importar essa função de sklearn.metrics, do contrário ela não funcionará.\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "\n",
        "predicoes = melhor.predict(x_azar) \n",
        "accuracy = accuracy_score(predicoes, y_azar) * 100\n",
        "\n",
        "print(\"Accuracy para os dados foi %.2f%%\" % accuracy)COPIAR CÓDIGO\n",
        "O console nos retornará:\n",
        "\n",
        "Accuracy para os dados foi 78.75%.Utilizamos o GridSearchCV do SKLearn para encontrarmos o melhor conjunto de hiperparâmetros em um espaço definido, de modo a otimizar a nossa métrica (accuracy). Quando tentamos analisar quão bem nosso algoritmo se sairia no mundo real, pegamos o melhor conjunto (representado por melhor) e utilizamos um predict() em cima de x_azar - ou seja, com todos os dados e uma única vez. Porém, durante o nosso processo de aprendizado, utilizamos o cross validation, e existem alguns cuidados que devemos tomar a esse respeito.\n",
        "\n",
        "Na documentação do SKLearn, encontramos uma seção sobre nested versus non-nested cross-validation. O texto afirma que quando estamos utilizando hiperparâmetros, fazendo, por exemplo, o GridSearchCV junto com o cross_validation_score, não devemos descobrir a nossa métrica por meio do predict(), mas sim com outro cross_valiation_score.\n",
        "\n",
        "Utilizar o predict() acaba sendo muito otimista, pois acabamos incorrendo em um vício sobre os dados que já tínhamos visto. Portanto, essa abordagem deve ser evitada.\n",
        "\n",
        "No nosso novo teste, importaremos cross_val_score de sklearn.model_selection. Em seguida, chamaremos cross_val_score(), passando busca, x_azar e y_azar. O cross validation será o mesmo que estávamos utilizando anteriormente (GroupKFold(n_splits=10), e os grupos serão dados.modelo.\n",
        "\n",
        "Esse código nos retornará vários scores.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = GroupKFold(n_splits=10), groups = dados.modelo)COPIAR CÓDIGO\n",
        "Tentando rodar esse código, receberemos um erro afirmando que o valor de groups não deve ser none, como se não tivéssemos passado nenhum valor para os grupos. Ou seja, de alguma forma groups não está chegando em GroupKFold() - e é exatamente isso que está acontecendo.\n",
        "\n",
        "Na verdade, isso ocorre por conta de um bug - o GroupKFold falha na validação cruzada aninhada, e existe até um tópico no GitHub do scikit sobre esse problema. É um bug antigo (o tópico foi criado em 2016), mas continua em aberto, pois é razoavelmente complicado implementar a correção dele.\n",
        "\n",
        "Como o Pandas não suporta nested validation com o GroupKFold, não conseguiremos prever o resultado para novos grupos. Como alternativa, usaremos o KFold comum, que precisa ser importado de sklearn.model_selection.\n",
        "\n",
        "Além disso, mudaremos o número de splits para 5, adicionaremos o parâmetro shuffle=True e removeremos o parâmetro groups de busca.fit().\n",
        "\n",
        "Como estamos rodando com KFold normal, essa estimativa é feita sem saber se o grupo é novo ou não.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Rodando esse código, teremos a seguinte tabela:\n",
        "\n",
        "mean_fit_time\tmean_score_time\tmean_test_score\tmean_train_score\tparam_criterion\tparam_max_depth\tparam_min_samples_leaf\tparam_min_samples_split\tparams\trank_test_score\t...\tsplit2_test_score\tsplit2_train_score\tsplit3_test_score\tsplit3_train_score\tsplit4_test_score\tsplit4_train_score\tstd_fit_time\tstd_score_time\tstd_test_score\tstd_train_score\n",
        "0.010685\t0.001431\t0.787\t0.787525\tgini\t3\t32\t32\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.8025\t0.783625\t0.793\t0.786\t0.7795\t0.7895\t0.001801\t0.000104\t0.009618\t0.002405\n",
        "0.010393\t0.001562\t0.787\t0.787525\tgini\t3\t32\t64\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.8025\t0.783625\t0.793\t0.786\t0.7795\t0.7895\t0.000547\t0.000144\t0.009618\t0.002405\n",
        "0.010549\t0.001502\t0.787\t0.787525\tgini\t3\t32\t128\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.8025\t0.783625\t0.793\t0.786\t0.7795\t0.7895\t0.000525\t0.000116\t0.009618\t0.002405\n",
        "0.010042\t0.001392\t0.787\t0.787525\tgini\t3\t64\t32\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.8025\t0.783625\t0.793\t0.786\t0.7795\t0.7895\t0.000671\t0.000181\t0.009618\t0.002405\n",
        "0.010203\t0.001338\t0.787\t0.787525\tgini\t3\t64\t64\t{'criterion': 'gini', 'max_depth': 3, 'min_sam...\t1\t...\t0.8025\t0.783625\t0.793\t0.786\t0.7795\t0.7895\t0.000668\t0.000098\t0.009618\t0.002405\n",
        "Agora podemos rodar o cross_val_score() como gostaríamos, passando KFold(n_splits=5, shuffle=True) no cross validation.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "scoresCOPIAR CÓDIGO\n",
        "Nossos resultados serão esses cinco valores:\n",
        "\n",
        "array([0.782 , 0.791 , 0.8075, 0.777 , 0.777 ])\n",
        "\n",
        "Com eles, é possível reconstruir a média e o intervalo. Para isso, criaremos uma função imprime_scores() que recebe scores. Na media, usaremos scores.mean() * 100, e no desvio scores.std() * 100.Já aprendemos que, quando temos um espaço de parâmetros com duas dimensões, podemos explorá-lo ponto a ponto. Isto é, transformamos espaços contínuos em espaços discretos e exploramos, nesses pontos, o nosso algorítimo.\n",
        "\n",
        "Por exemplo, se estamos trabalhando com um algorítimo de DecisionTreeClassifier que tem os parâmetros max_depth e min_samples_leaf, podemos testar cada um desses parâmetros com um valor específico. Depois de medirmos o resultado, repetimos o processo para o próximo parâmetro.\n",
        "\n",
        "Dessa forma, exploramos o espaço até completarmos o grid todo. Por exemplo, se temos 15 condições para cada parâmetro, rodamos o algorítimo 225 vezes para explorar esse espaço por completo.\n",
        "\n",
        "Mas e quando temos 3 parâmetros, cada um com uma determinada quantidade de condições? Nesse caso, ainda poderíamos plotar esses dados em um gráfico 3D... mas e se tivéssemos 4 parâmetros ou mais?\n",
        "\n",
        "Supondo que tivéssemos 3 parâmetros com 64 condições cada um, e um parâmetro com apenas 2 condições. Nessa situação, teríamos que explorar 524.288 possibilidades de parâmetros. Se cada uma dessas explorações levasse 5 minutos (o que é um exemplo razoável), seriam necessários 1820 dias para testar todas essas possibilidades. Se estivéssemos rodando esse algorítimo em 5 máquinas, ainda assim levaríamos 1 ano para terminar o processo.\n",
        "\n",
        "Vamos analisar o grid de duas dimensões abaixo:\n",
        "\n",
        "grid com dois eixos de 15 pontos cada, gerando 225 elementos\n",
        "\n",
        "Mesmo que não haja garantia disso, esperamos que os valores representados no grid tenham resultados próximos aos seus vizinhos. Ou seja, pode não existir uma mudança brusca entre pontos muito próximos do nosso espaço discretizado de parâmetros.\n",
        "\n",
        "Com isso em mente, ao invés de tentarmos explorar todo o grid (o que é feito no grid search), poderíamos buscar pontos aleatoriamente (random search). E é exatamente isso que faremos agora.\n",
        "\n",
        "Começaremos essa busca aleatória ao final do projeto no qual trabalhamos no curso anterior. Se você não fez o curso, pode fazer o download do projeto neste link ou visualizar os arquivos no GitHub.\n",
        "\n",
        "Para organizarmos nosso trabalho, adicionaremos uma célula de texto indicando onde se inicia o RandomSearch. Esse processo de busca é bastante parecido com tudo o que fizemos anteriormente, e também se inicia definindo um espaço de parâmetros a ser explorado.\n",
        "\n",
        "Portanto, começaremos copiando o código que criamos para GridSearchCV:\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFraframe(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Em seguida, alteraremos os campos em que GridSearchCV aparece para RandomizedSearchCV. Manteremos a mesma SEED e o mesmo espaço de parâmetros (com 36 possibilidades). Quando trabalhos com processos aleatórios, é muito comum que o modelo contenha um parâmetro random_state para manter a consistência entre todas as execuções. No caso, esse parâmetro receberá nosso SEED como valor.\n",
        "\n",
        "Dentre essas 36 possibilidades de combinações de parâmetros, quantas queremos rodar? Se executarmos todas, estaremos fazendo exatamente a mesma busca que com o GridSearchCV, alterando apenas a ordem. Ou seja, devemos executar somente algumas.\n",
        "\n",
        "Um dos parâmetros que RandomizedSearchCV pode receber é o número de iterações - n_iter. A ideia é, nesse momento, rodarmos apenas 16 dessas possibilidades:\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros, \n",
        "                    n_iter = 16,\n",
        "                    cv = KFold(n_splits = 5),\n",
        "                          random_state = SEED)\n",
        "\n",
        "\n",
        "busca.fit(x_azar, y_azar,groups = dados.modelo)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Após a execução desse código, queremos saber quão bem se saiu o melhor classificador. Da mesma forma que no GridSearchCV, encontraremos uma resposta com cross_val_score() (nested cross validation).\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "scoresCOPIAR CÓDIGO\n",
        "O resultado na tela será um array de cinco valores:\n",
        "\n",
        "array([0.7755, 0.78 , 0.8055, 0.7855, 0.774 ])\n",
        "\n",
        "Também iremos imprimir a acurácia média dessas cinco amostras e o intervalo que obtivemos:\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "imprime_score(scores)COPIAR CÓDIGO\n",
        "Accuracy médio 78.69\n",
        "\n",
        "Intervalo [76.70, 80.68]\n",
        "\n",
        "Em seguida, para encontrarmos o melhor estimador, atribuiremos a função busca.best_estimator_ à uma variável melhor e imprimiremos essa variável na tela.\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=128, min_samples_split=128,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "            splitter='best')COPIAR CÓDIGO\n",
        "Isso significa que o melhor estimador teve o critério gini, a profundidade máxima 5, o mínimo de elementos na folha 128 e, e 128 como o mínimo de splits antes de tomar uma decisão. Tivemos uma acurácia média de 78.69%, em um intervalo entre 76.70% e 80.68%.\n",
        "\n",
        "Repare que executando menos da metade das buscas, obtivemos uma acurácia média e um intervalo muito parecidos com aqueles do GridSearchCV (que tinha a média 78.68% e o intervalo 76.85% a 80.55).\n",
        "\n",
        "Nesse ponto, também podemos gerar a árvore de decisões:\n",
        "\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True,\n",
        "                        class_names=[\"não\", \"sim\"],\n",
        "                        feature_names = features)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graphCOPIAR CÓDIGO\n",
        "Como a árvore é bem grande, mostraremos somente parte dela nessa página:\n",
        "\n",
        "representação visual da árvore de decisões gerada a partir da melhor combinação de parâmetros encontrada pelo randomsearchCV\n",
        "\n",
        "Na prática, a utilização do RandomizedSearchCV nos permite encontrar valores muito próximos aos que mais otimizarão nossos estimadores, sem que seja necessário explorar todo o espaço de parâmetros (o que muitas vezes é impossível).Nós exploramos aleatoriamente o nosso espaço de parâmetros, mas fizemos isso de maneira bem restrita. Anteriormente, devido às limitações de processamento do GridSearchCV (principalmente em relação ao tempo), nós utilizamos somente 36 combinações.\n",
        "\n",
        "Porém, seria mais interessante explorarmos ainda mais parâmetros no nosso algorítimo - por exemplo, um max_depth que recebesse 10, 20, 30 ou até que não tivesse limites (o que é possível com None, segundo a documentação do próprio GridSearchCV).\n",
        "\n",
        "A ideia é executarmos novamente o RandomizedSearchCV, mas com diferentes customizações nesse espaço de parâmetros. Por exemplo, em max_depth, ao invés de termos somente os valores 3 e 5, teremos um conjunto discreto de números inteiros (3, 5, 10, 15, 20, 30) com a adição do valor None.\n",
        "\n",
        "Em min_samples_split e min_samples_leaf, queremos qualquer número inteiro aleatório entre 32 e 128. Para isso, precisaremos de uma função de aleatoriedade que devolva um número aleatório a cada execução - neste caso, randint (random integer). Essa função deve ser importada do pacote scipy,stats.\n",
        "\n",
        "Segundo a documentação do SciPy randint, ele percorre desde o número mais baixo (low, no nosso código 32) até o número anterior ao mais alto (high - 1, ou seja, 127).\n",
        "\n",
        "Isso significa que agora temos muito mais possibilidades de combinações: são 7 elementos para max_depth, 96 para min_samples_split e min_samples_leaf, e 2 para criterion - no total, 129.024 combinações diferentes de parâmetros.\n",
        "\n",
        "Desse número, executaremos apenas 16, a mesma quantidade que estávamos executando anteriormente, mas com um espaço de parâmetros muito maior e mais complexo:\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5, 10, 15, 20, 30, None],\n",
        "    \"min_samples_split\" : randint(32, 128),\n",
        "    \"min_samples_leaf\" : randint(32, 128),\n",
        "    \"criterion\" : [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros, \n",
        "                    n_iter = 16,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True),\n",
        "                          random_state = SEED)\n",
        "\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Em seguida, imprimiremos os resultados e o melhor conjunto na tela:\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)COPIAR CÓDIGO\n",
        "Como resposta, teremos algo como:\n",
        "\n",
        "Accuracy médio 78.71\n",
        "\n",
        "Intervalo [77.49, 79.93]\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
        "\n",
        "        max_features=None, max_leaf_nodes=None,\n",
        "\n",
        "        min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "\n",
        "        min_samples_leaf=71, min_samples_split=100,\n",
        "\n",
        "        min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "\n",
        "        splitter='best')COPIAR CÓDIGO\n",
        "Nossa acurácia foi bem próxima dos resultados anteriores, mas o ponto é que demoramos um tempo 8.000 vezes menor para explorar esse espaço de parâmetros, obtendo resultados tão bons quanto conseguiríamos com o GridSearchCV.\n",
        "\n",
        "def imprime_score(scores):\n",
        "  media = scores.mean() * 100\n",
        "  desvio = scores.std() * 100\n",
        "  print(\"Accuracy médio %.2f\" % media)\n",
        "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))COPIAR CÓDIGO\n",
        "Em seguida, basta chamarmos a função imprime_score(scores). O resultado será:\n",
        "\n",
        "Accuracy médio 78.69\n",
        "\n",
        "Intervalo [76.39, 80.99]\n",
        "\n",
        "Agora vamos imprimir a árvore de decisão que encontramos como nosso melhor estimador:\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True,\n",
        "                          class_names=[\"não\",\"sim\"],\n",
        "                          feature_names=features)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graphCOPIAR CÓDIGO\n",
        "\n",
        "\n",
        "Repare que a árvore tem 3 níveis de profundidade (max_depth=3, ou seja, três decisões a serem tomadas), e as folhas e os splits (min_samples_leaf e min_samples_split, respectivamente) têm um mínimo de 32 samples cada. Além disso, as decisões de quebras seguem o critério de gini ao invés de entropy.\n",
        "\n",
        "Esse é o melhor modelo real que iremos utilizar agora que exploramos o espaço de hiperparâmetros. Esse tipo de exploração com grid, no qual cada espaço é analisado separadamente, é válido e funciona. Porém, é um processo demorado, e existem otimizações que podem ser feitas para contornar isso.Nós exploramos aleatoriamente o nosso espaço de parâmetros, mas fizemos isso de maneira bem restrita. Anteriormente, devido às limitações de processamento do GridSearchCV (principalmente em relação ao tempo), nós utilizamos somente 36 combinações.\n",
        "\n",
        "Porém, seria mais interessante explorarmos ainda mais parâmetros no nosso algorítimo - por exemplo, um max_depth que recebesse 10, 20, 30 ou até que não tivesse limites (o que é possível com None, segundo a documentação do próprio GridSearchCV).\n",
        "\n",
        "A ideia é executarmos novamente o RandomizedSearchCV, mas com diferentes customizações nesse espaço de parâmetros. Por exemplo, em max_depth, ao invés de termos somente os valores 3 e 5, teremos um conjunto discreto de números inteiros (3, 5, 10, 15, 20, 30) com a adição do valor None.\n",
        "\n",
        "Em min_samples_split e min_samples_leaf, queremos qualquer número inteiro aleatório entre 32 e 128. Para isso, precisaremos de uma função de aleatoriedade que devolva um número aleatório a cada execução - neste caso, randint (random integer). Essa função deve ser importada do pacote scipy,stats.\n",
        "\n",
        "Segundo a documentação do SciPy randint, ele percorre desde o número mais baixo (low, no nosso código 32) até o número anterior ao mais alto (high - 1, ou seja, 127).\n",
        "\n",
        "Isso significa que agora temos muito mais possibilidades de combinações: são 7 elementos para max_depth, 96 para min_samples_split e min_samples_leaf, e 2 para criterion - no total, 129.024 combinações diferentes de parâmetros.\n",
        "\n",
        "Desse número, executaremos apenas 16, a mesma quantidade que estávamos executando anteriormente, mas com um espaço de parâmetros muito maior e mais complexo:\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5, 10, 15, 20, 30, None],\n",
        "    \"min_samples_split\" : randint(32, 128),\n",
        "    \"min_samples_leaf\" : randint(32, 128),\n",
        "    \"criterion\" : [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros, \n",
        "                    n_iter = 16,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True),\n",
        "                          random_state = SEED)\n",
        "\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Em seguida, imprimiremos os resultados e o melhor conjunto na tela:\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)COPIAR CÓDIGO\n",
        "Como resposta, teremos algo como:\n",
        "\n",
        "Accuracy médio 78.71\n",
        "\n",
        "Intervalo [77.49, 79.93]\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
        "\n",
        "        max_features=None, max_leaf_nodes=None,\n",
        "\n",
        "        min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "\n",
        "        min_samples_leaf=71, min_samples_split=100,\n",
        "\n",
        "        min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "\n",
        "        splitter='best')COPIAR CÓDIGO\n",
        "Nossa acurácia foi bem próxima dos resultados anteriores, mas o ponto é que demoramos um tempo 8.000 vezes menor para explorar esse espaço de parâmetros, obtendo resultados tão bons quanto conseguiríamos com o GridSearchCV.Queremos ordenar os resultados da nossa busca pelo score médio (mean_test_score). Para isso, usaremos o sort_values, passando o nome dessa coluna e o argumento ascending=False (negando a ordenação crescente da função). Nesse momento, não estamos levando em consideração o intervalo de confiança (com duas vezes o desvio padrão).\n",
        "\n",
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)COPIAR CÓDIGO\n",
        "Com a função iterrows, iremos iterar por cada uma das linhas dessa tabela do pandas. O iterrows é um gerador de iteração que devolve dois elementos em cada uma das linhas: o índice e a linha. Começaremos imprimindo os índices:\n",
        "\n",
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media.iterrows():\n",
        "  print(indice)COPIAR CÓDIGO\n",
        "Como resposta, teremos algo como:\n",
        "\n",
        "9\n",
        "\n",
        "1\n",
        "\n",
        "5\n",
        "\n",
        "3\n",
        "\n",
        "14\n",
        "\n",
        "(...)\n",
        "\n",
        "Esses são os índices ordenados do maior mean_test_score para o menor. Agora, imprimiremos o mean_test_score, o desvio padrão do teste (std_test_score) e os parâmetros que geraram esse resultado (params, que devolve um objeto com todos os valores parametrizados).\n",
        "\n",
        "Multiplicando o std_test_score por 2, chegaremos a um intervalo aproximado do que seria o desvio padrão. Por fim, definiremos que mean_test_score e std_test_score terão três casas decimais de ponto flutuante:\n",
        "\n",
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media.iterrows():\n",
        "  print(\"%.3f +- (%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))COPIAR CÓDIGO\n",
        "Nossos resultados serão parecidos com esses:\n",
        "\n",
        "0.787 +- (0.019) {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 71, 'min_samples_split': 100}\n",
        "\n",
        "0.784 +- (0.024) {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 73, 'min_samples_split': 72}\n",
        "\n",
        "0.784 +- (0.024) {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 64, 'min_samples_split': 67}\n",
        "\n",
        "0.781 +- (0.017) {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 108, 'min_samples_split': 110}\n",
        "\n",
        "0.780 +- (0.019) {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 125, 'min_samples_split': 59}\n",
        "\n",
        "(...)\n",
        "\n",
        "Essa é uma forma resumida de imprimir os resultados que recebíamos na tabela do pandas. Com 16 combinações, é uma análise razoável. Mas e se quiséssemos explorar um número maior - por exemplo, 64? Imprimindo os resultados dessa exploração na tela, encontraremos os mesmos RandomizedSearchCV irá explorar os parâmetros da mesma maneira.\n",
        "\n",
        "Se forçássemos a exploração com um SEED diferente (por exemplo, 564), receberíamos outros valores:\n",
        "\n",
        "0.787 +- (0.011) {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 33, 'min_samples_split': 77}\n",
        "\n",
        "0.787 +- (0.011) {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 38, 'min_samples_split': 113}\n",
        "\n",
        "0.787 +- (0.011) {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 53, 'min_samples_split': 60}\n",
        "\n",
        "0.787 +- (0.011) {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 61, 'min_samples_split': 86}\n",
        "\n",
        "0.787 +- (0.011) {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 49, 'min_samples_split': 58}\n",
        "\n",
        "Porém, essa exploração é aleatória, e não é uma prática comum mudarmos o SEED para encontrar valores ótimos - já que, como podemos perceber, os valores são bastante próximos entre si. Na verdade, esses resultados também poderiam ser muito distantes entre si, dependendo de várias condições.\n",
        "\n",
        "Para encerrar, faremos a validação cruzada aninhada e imprimiremos o melhor conjunto de parâmetros encontrado para esse estimador:\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)COPIAR CÓDIGO\n",
        "Na tela, teremos:\n",
        "\n",
        "Accuracy médio 78.69\n",
        "\n",
        "Intervalo [77.64, 79.74]\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
        "\n",
        "max_features=None, max_leaf_nodes=None,\n",
        "\n",
        "min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "\n",
        "min_samples_leaf=53, min_samples_split=60,\n",
        "\n",
        "min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "\n",
        "splitter='best')\n",
        "\n",
        "Esse é o resultado do nosso treino com uma busca aleatória contendo 64 tentativas. Repare que ainda conseguimos executar o código rapidamente, e com um computador mais potente conseguiríamos rodar ainda mais valores para o nosso estimador.\n",
        "\n",
        "Mas será que o RandomizedSearchCV é mesmo melhor que o GridSearchCV?Fazer um espaçamento de parâmetros que contém números aleatórios entre 32 a 128;\n",
        "Utilizar o randint do scipy.stats;\n",
        "Explorar espaços.É hora de compararmos os resultados do GridSearchCV com os do RandomizedSearchCV.\n",
        "\n",
        "Logicamente, estamos utilizando um exemplo de cada um desses algorítimos. É possível encontrar, na literatura e na prática, outros exemplos mostrando que buscar por completo um espaço discretizado com GridSearchCV trará a certeza de que os valores encontrados são os mais otimizados dentro desse espaço. Porém, o RandomizedSearchCV permite um controle maior sobre o tempo e o custo computacional/financeiro de otimização do modelo.\n",
        "\n",
        "Além disso, se o grid tiver valores infinitos entre 0 e 1, será impossível explorar todo esse espaço, sendo necessário pegar exemplares aleatórios ou discretizar a seleção de alguma forma.\n",
        "\n",
        "Começaremos nossa comparação pegando o código que criamos para GridSearchCV\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Até o momento, vínhamos utilizando o DecisionTreeClassifier, um dos diversos classificadores baseados em árvores de decisão. Existem outros classificadores que, ao invés de tentarem uma única árvore, tentam diversas árvores. Um desses, bem famoso, é o ensemble RandomForestClassifier.\n",
        "\n",
        "O sklearn ensemble RandomForestClassifier é um conjunto de classificadores que atuam de forma uníssona para chegar a uma conclusão. Além de possuir os diversos hiperparâmetros que já conhecemos antes, esse classificador possui alguns novos, como max_features (o número máximo de colunas de X utilizado para chegar a uma decisão), e o n_estimators (a quantidade de estimadores que serão treinados), para o qual atribuiremos os valores 10 e 100.\n",
        "\n",
        "Mais detalhes sobre esse algorítimo podem ser encontrados na documentação do RandomForestClassifier.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : [10, 100]\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Com essas atribuições, já temos 72 combinações a serem exploradas. Porém, usaremos mais um último parâmetro, chamado bootstrap.\n",
        "\n",
        "Ao invés do algorítimo tentar treinar os classificadores para todos os dados que estamos passando, correndo o risco de um overfitting, cada árvore é treinada com uma amostra desses dados. O bootstrap permite definir se um mesmo elemento pode fazer parte de diferentes amostras. Passando os valores True e False, dobraremos o nosso espaço de parâmetros, terminando com 144 combinações.\n",
        "\n",
        "Antes de rodarmos a busca, não iremos medir somente a acurácia, mas também o tempo gasto computacionalmente para chegarmos aos nossos modelos. Para isso, importaremos time e passaremos dois momentos: tic, quando o treino começa; e tac, quando ele termina.\n",
        "\n",
        "O tempo_que_passou será tac - tic, e será impresso na tela com print(\"Tempo %.2f segundos\" % tempo_que_passou):\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time \n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : [10, 100],\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "tic = time.time()\n",
        "busca = GridSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Na tela serão impressos o dataframe com os nossos resultados e o tempo total dessa execução - no nosso caso, 255 segundos, que é cerca de 4,5 minutos. Vamos imprimir os 5 melhores resultados:\n",
        "\n",
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))COPIAR CÓDIGO\n",
        "0.780 +-(0.020) {'bootstrap': False, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 32, 'min_samples_split': 64, 'n_estimators': 10}\n",
        "\n",
        "0.778 +-(0.020) {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 32, 'min_samples_split': 128, 'n_estimators': 10}\n",
        "\n",
        "0.778 +-(0.030) {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 64, 'min_samples_split': 64, 'n_estimators': 10}\n",
        "\n",
        "0.778 +-(0.027) {'bootstrap': False, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 64, 'min_samples_split': 64, 'n_estimators': 10}\n",
        "\n",
        "0.778 +-(0.033) {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 64, 'min_samples_split': 64, 'n_estimators': 100}\n",
        "\n",
        "Conseguimos uma média de 0.78 e um desvio padrão bem controlado, de apenas 0.02. Agora rodaremos o código do cross_validation_score, também medindo o tempo dessa execução:\n",
        "\n",
        "tic = time.time()\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "tac = time.time()\n",
        "tempo_passado = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_passado)\n",
        "\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)COPIAR CÓDIGO\n",
        "Esse processo irá demorar tanto que o próprio Google Colab encerrará a conexão com a máquina virtual do Python. Ou seja, seria necessário rodarmos o código na nossa própria máquina para que a execução chegasse ao seu fim.Comparar o grid search com random search;\n",
        "Utilizar o bootstrap para pegar um elemento ou não pegar;\n",
        "Utilizar o RandomizedSearchCV para árvore de decisão.Para começarmos a comparação com o RandomizedSearchCV, copiaremos o código criado na aula anterior:\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time \n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : [10, 100],\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "tic = time.time()\n",
        "busca = GridSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Substituiremos o campo GridSearchCV() por RandomizedSearchCV(), mantendo exatamente os mesmos parâmetros, com a exceção de n_iter = 20 - ou seja, buscaremos 20 iterações nesse espaço de parâmetros.\n",
        "\n",
        "tic = time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    n_iter = 20,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)COPIAR CÓDIGO\n",
        "No nosso caso, essa execução levou cerca de 37 segundos. Vamos imprimir os 5 melhores resultados:\n",
        "\n",
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))COPIAR CÓDIGO\n",
        "0.776 +-(0.025) {'n_estimators': 100, 'min_samples_split': 32, 'min_samples_leaf': 32, 'max_depth': 5, 'criterion': 'gini', 'bootstrap': False}\n",
        "\n",
        "0.776 +-(0.023) {'n_estimators': 100, 'min_samples_split': 32, 'min_samples_leaf': 128, 'max_depth': 3, 'criterion': 'gini', 'bootstrap': False}\n",
        "\n",
        "0.776 +-(0.024) {'n_estimators': 100, 'min_samples_split': 64, 'min_samples_leaf': 32, 'max_depth': 5, 'criterion': 'entropy', 'bootstrap': True}\n",
        "\n",
        "0.775 +-(0.032) {'n_estimators': 10, 'min_samples_split': 32, 'min_samples_leaf': 64, 'max_depth': 3, 'criterion': 'entropy', 'bootstrap': False}\n",
        "\n",
        "0.775 +-(0.035) {'n_estimators': 10, 'min_samples_split': 32, 'min_samples_leaf': 32, 'max_depth': 5, 'criterion': 'gini', 'bootstrap': True}\n",
        "\n",
        "Quando exploramos as 144 combinações do nosso grid, tínhamos chegado à média 0.780 com +- 0.020 de desvio padrão - ou seja, valores muito próximos dos que encontramos com o RandomSearchCV. Lembrando que esses valores são relativamente próximos - ou seja, essa interpretação depende muito da situação em que nosso algorítimo é aplicado. Em casos de vida ou morte, por exemplo, uma diferença de 0.004 pode ser significante.\n",
        "\n",
        "Dessa vez, é até viável executarmos a exploração do cross_validation_score():\n",
        "\n",
        "tic = time.time()\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "tac = time.time()\n",
        "tempo_passado = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_passado)\n",
        "\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)COPIAR CÓDIGO\n",
        "Tempo 154.63 segundos\n",
        "\n",
        "Accuracy médio 77.59\n",
        "\n",
        "Intervalo [76.47, 78.71]\n",
        "\n",
        "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
        "\n",
        "max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
        "\n",
        "min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "\n",
        "min_samples_leaf=32, min_samples_split=32,\n",
        "\n",
        "min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
        "\n",
        "oob_score=False, random_state=None, verbose=0,\n",
        "\n",
        "warm_start=False)\n",
        "\n",
        "Em cerca de 2 minutos e meio obtivemos os resultados do cross_validation_score() com o RandomizedSearchCV. Enquanto isso, somente com 144 possibilidades, não conseguimos rodar a mesma função com do GridSearchCV remotamente. Imagine então se, para min_samples_split e min_samples_leaf, utilizássemos o parâmetro randint para iterar entre qualquer número entre 32 e 129? Ou mesmo para iterar entre 10 e 101 em n_estimators e entre 3 e 6 em max_depth?\n",
        "\n",
        "Nesse caso, teríamos 10.274.628 combinações (91*3*97*97*2*2). Parece inviável, não é? Já com o RandomSearchCV, poderíamos até mesmo controlar o tempo (e o custo computacional) dispensado a essa tarefa. Por exemplo, se levamos cerca de meio minuto para iterar por 20 possibilidades randômicas, podemos estimar que iterar por 80 possibilidades levará cerca de 2 minutos. Vamos testar?\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : randint(10, 101),\n",
        "    \"max_depth\" : randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "tic = time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    n_iter = 80,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Nesse caso, levamos cerca de 125 segundos (2 minutos) para rodar o código - ou seja, nossa estimativa deu certo. Lembre-se que esse tipo de cálculo vai depender do algorítimo e de suas especificidades.\n",
        "\n",
        "Dentro desse espaço de parâmetros, vamos imprimir as 5 melhores combinações:\n",
        "\n",
        "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))COPIAR CÓDIGO\n",
        "0.779 +-(0.025) {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 84, 'min_samples_split': 89, 'n_estimators': 48}\n",
        "\n",
        "0.778 +-(0.031) {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 32, 'min_samples_split': 96, 'n_estimators': 18}\n",
        "\n",
        "0.778 +-(0.032) {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 121, 'min_samples_split': 47, 'n_estimators': 27}\n",
        "\n",
        "0.777 +-(0.024) {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 96, 'min_samples_split': 98, 'n_estimators': 11}\n",
        "\n",
        "0.777 +-(0.029) {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 63, 'min_samples_split': 88, 'n_estimators': 69}\n",
        "\n",
        "O melhor resultado que encontramos foi 0.79 de média com +- 0.025 de desvio padrão, muito próximo dos anteriores. Lembrando que, com o GridSearchCV, levamos cerca de 4 minutos e meio para chegar aos resultados explorando um espaço muito menor.\n",
        "\n",
        "Repare que, mesmo nesse espaço enorme de mais de 10 milhões de combinações, não tivemos uma variabilidade muito grande de resultados. Mesmo os últimos 5 elementos dessa lista, que têm uma qualidade menor, não são tão discrepantes:\n",
        "\n",
        "0.770 +-(0.024) {'bootstrap': True, 'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 81, 'min_samples_split': 59, 'n_estimators': 16}\n",
        "\n",
        "0.768 +-(0.018) {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 43, 'min_samples_split': 33, 'n_estimators': 50}\n",
        "\n",
        "0.767 +-(0.037) {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 54, 'min_samples_split': 86, 'n_estimators': 13}\n",
        "\n",
        "0.766 +-(0.043) {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 67, 'min_samples_split': 76, 'n_estimators': 32}\n",
        "\n",
        "0.758 +-(0.033) {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 56, 'min_samples_split': 71, 'n_estimators': 14}\n",
        "\n",
        "Dependendo do algorítimo e dos dados, pode ser que a escolha de um hiperparâmetro faça uma diferença muito grande no sistema como um todo. Como exemplo, você pode consultar o artigo Hyperparameters Matter, que analisa a importância dos hiperparâmetros no contexto de recomendações com Word2vec.\n",
        "\n",
        "Ainda falta explorarmos um espaço que não seja baseado em árvores de decisão, como o SVC. A seguir, iremos estudar como explorar dois tipos de algorítimos ao mesmo tempo dentro do SVC.Agora que fizemos algumas comparações entre o GridSearchCV e o RandomizedSearchCV, vamos analisar alguns casos diferentes.\n",
        "\n",
        "Por exemplo, pode ser que não seja possível, computacionalmente, rodar um cross validation, independentemente do fold. Nesse caso, como faríamos uma otimização de hiperparâmetros sem cross validation? Teríamos que, mesmo assim, tentar separar os dados entre treino e teste.\n",
        "\n",
        "Até o momento, estávamos trabalhando com duas fases: a fase de treino e teste, e a fase de validação com cross_val_score() (nested cross validation). Na prática, agora teremos três fases: uma fase de treino do modelo (ou de vários modelos) na busca de otimizar os hiperparâmetros; uma fase de teste, comparando os modelos para encontrar os melhores resultados; e uma fase de validação, tentando alcançar uma estimativa real desse algorítimo.\n",
        "\n",
        "Ou seja, teremos que separar três conjuntos de dados, e não mais dois, como vínhamos fazendo com a função train_test_split().\n",
        "\n",
        "No sklearn.model_selection, precisaremos encontrar um algorítimo de separação que não seja um KFold (que só separa uma única vez, sem validação cruzada). Existem algorítimos que fazem isso, como o ShuffleSplit, que irá aleatorizar os dados e quebrá-los uma única vez; ou o StratifiedShuffleSplit, que irá aleatorizar a ordem dos dados e quebrá-los de acordo com a estratificação dos dados que passarmos para ele. É esse algorítimo que utilizaremos agora, independentemente de trabalharmos com o GridSearchCV ou com o RandomizedSearchCV.\n",
        "\n",
        "Para começar, copiaremos o último código que escrevemos para RandomizedSearchCV. Nele, faremos a importação do StratifiedShuffleSplit e criaremos uma variável split recebendo a parametrização desse algorítimo - no nosso caso, n_splits = 1 e test_size = 0.2 (reservando apenas 20% dos nossos dados para o teste).\n",
        "\n",
        "Ao invés de 80 iterações, faremos apenas 5, acelerando a execução do código:\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : randint(10, 101),\n",
        "    \"max_depth\" : randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
        "\n",
        "tic = time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    n_iter = 5,\n",
        "                    cv = split)\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Quando fazemos um cross validation com 2 folds, ele executa duas vezes o algorítimo com 50% dos dados em cada uma das vezes. Diferentemente disso, dessa vez separamos 80% dos dados para o teste, e 20% para o treino, rodando o algorítimo uma única vez.\n",
        "\n",
        "Sem a cross validation, teremos que encontrar outra forma de obter os resultados finais desse algorítimo. Precisaremos, então, de um conjunto de dados inédito para executar a validação do nosso modelo. Mas como faremos isso se todos os dados foram utilizados no treino e no teste?\n",
        "\n",
        "A resposta na verdade é bem simples: a separação desses dados deve ser feita de antemão. Portanto, antes de treinarmos o modelo com x_azar e y_azar, separaremos uma amostra dos dados para a fase que chamaremos de validação.\n",
        "\n",
        "Vamos supor que queremos 60% para treino, 20% para teste (também chamado de \"dev teste\") e 20% para a validação final. Faremos isso utilizando o train_test_split(), que deverá ser importado do sklearn.model_selection.\n",
        "\n",
        "Para essa função, passaremos os dados x_zar, y_azar, e os parâmetros test_size:0,2, shuffle=True, stratify=y_azar. Nesse caso, estamos separando os 20% dos dados para validação, mesmo que o parâmetro do algorítimo se chame test_size.\n",
        "\n",
        "Essa funçã nos devolve x_train, x_test, y_train e y_test. Vamos nomear cada um desses objetos como x_treino_teste, x_validacao, y_treino_teste, y_validacao.\n",
        "\n",
        "Também precisaremos passar o SEED que nosso código seguirá. Para garantirmos que as dimensões dos dados estão separadas corretamente, imprimiremos todas aquelas variáveis na tela:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "x_treino_teste, x_validacao, y_treino_teste, y_validacao = train_test_split(x_azar, y_azar, test_size=0.2, shuffle=True, stratify=y_azar)\n",
        "\n",
        "print(x_treino_teste.shape)\n",
        "print(x_validacao.shape)\n",
        "print(y_treino_teste.shape)\n",
        "print(y_validacao.shape)COPIAR CÓDIGO\n",
        "Como retorno, teremos:\n",
        "\n",
        "(8000, 3) (2000, 3) (8000,) (2000,)\n",
        "\n",
        "Ou seja, temos:\n",
        "\n",
        "8.000 elementos e 3 colunas para treino do algorítimo\n",
        "2.000 elementos para teste\n",
        "1 coluna para verificar as features e a classe do algorítimo\n",
        "Agora, na função busca.fit(), deveremos passar as variáveis atualizadas (x_treino_teste e y_treino_teste). Também devemos nos atentar ao StratifiedShuffleSplit(): estamos passando test_size=0.2, mas 20% de 80% são 16%. Na verdade, precisamos atribuir test_size=0.25, ou seja, 25%.\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : randint(10, 101),\n",
        "    \"max_depth\" : randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25)\n",
        "\n",
        "tic = time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    n_iter = 5,\n",
        "                    cv = split)\n",
        "busca.fit(x_treino_teste, y_treino_teste)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Agora podemos validar nossos estimadores com os dados que encontramos. A maneira mais simples de fazer isso é com o cross_val_score(), utilizando split ao invés de KFold. Além disso, passaremos x_validacao e y_validacao ao invés de x_azar e y_azar:\n",
        "\n",
        "tic = time.time()\n",
        "scores = cross_val_score(busca, x_validacao, y_validacao, cv = split)\n",
        "tac = time.time()\n",
        "tempo_passado = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_passado)\n",
        "\n",
        "scoresCOPIAR CÓDIGO\n",
        "Tempo 0.57 segundos\n",
        "\n",
        "array([0.774])\n",
        "\n",
        "O resultado é um único 0.074 - como só tivemos um teste e uma validação, removemos a impressão da média e do intervalo.\n",
        "\n",
        "O cross validation é um processo bastante interessante e prático, e inclusive poderíamos criar um pipeline que o fizesse de uma só vez. Porém, quando existem motivos para não utilizarmos o cross validation, devemos nos atentar a alguns detalhes importantes - por exemplo, à perda do intervalo de resultados.\n",
        "\n",
        "Existem alternativas para fazer a separação dos dados em três grupos, como utilizar o Numpy ou fazer a estratificação manualmente. Na prática, preferimos utilizar o train_test_split() do próprio SKLearn para separar os dados de validação.\n",
        "\n",
        "Nós ainda poderíamos rodar o algorítimo StratifiedShuffleSplit() mais de uma vez (n_splits=5, por exemplo), obtendo resultados mais parecidos com um processo de cross validation - inclusive com diversos scores para analisarmos. Porém, as proporções podem ser diferentes, o que exigiria alguns cuidados.Agora que fizemos algumas comparações entre o GridSearchCV e o RandomizedSearchCV, vamos analisar alguns casos diferentes.\n",
        "\n",
        "Por exemplo, pode ser que não seja possível, computacionalmente, rodar um cross validation, independentemente do fold. Nesse caso, como faríamos uma otimização de hiperparâmetros sem cross validation? Teríamos que, mesmo assim, tentar separar os dados entre treino e teste.\n",
        "\n",
        "Até o momento, estávamos trabalhando com duas fases: a fase de treino e teste, e a fase de validação com cross_val_score() (nested cross validation). Na prática, agora teremos três fases: uma fase de treino do modelo (ou de vários modelos) na busca de otimizar os hiperparâmetros; uma fase de teste, comparando os modelos para encontrar os melhores resultados; e uma fase de validação, tentando alcançar uma estimativa real desse algorítimo.\n",
        "\n",
        "Ou seja, teremos que separar três conjuntos de dados, e não mais dois, como vínhamos fazendo com a função train_test_split().\n",
        "\n",
        "No sklearn.model_selection, precisaremos encontrar um algorítimo de separação que não seja um KFold (que só separa uma única vez, sem validação cruzada). Existem algorítimos que fazem isso, como o ShuffleSplit, que irá aleatorizar os dados e quebrá-los uma única vez; ou o StratifiedShuffleSplit, que irá aleatorizar a ordem dos dados e quebrá-los de acordo com a estratificação dos dados que passarmos para ele. É esse algorítimo que utilizaremos agora, independentemente de trabalharmos com o GridSearchCV ou com o RandomizedSearchCV.\n",
        "\n",
        "Para começar, copiaremos o último código que escrevemos para RandomizedSearchCV. Nele, faremos a importação do StratifiedShuffleSplit e criaremos uma variável split recebendo a parametrização desse algorítimo - no nosso caso, n_splits = 1 e test_size = 0.2 (reservando apenas 20% dos nossos dados para o teste).\n",
        "\n",
        "Ao invés de 80 iterações, faremos apenas 5, acelerando a execução do código:\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : randint(10, 101),\n",
        "    \"max_depth\" : randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
        "\n",
        "tic = time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    n_iter = 5,\n",
        "                    cv = split)\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Quando fazemos um cross validation com 2 folds, ele executa duas vezes o algorítimo com 50% dos dados em cada uma das vezes. Diferentemente disso, dessa vez separamos 80% dos dados para o teste, e 20% para o treino, rodando o algorítimo uma única vez.\n",
        "\n",
        "Sem a cross validation, teremos que encontrar outra forma de obter os resultados finais desse algorítimo. Precisaremos, então, de um conjunto de dados inédito para executar a validação do nosso modelo. Mas como faremos isso se todos os dados foram utilizados no treino e no teste?\n",
        "\n",
        "A resposta na verdade é bem simples: a separação desses dados deve ser feita de antemão. Portanto, antes de treinarmos o modelo com x_azar e y_azar, separaremos uma amostra dos dados para a fase que chamaremos de validação.\n",
        "\n",
        "Vamos supor que queremos 60% para treino, 20% para teste (também chamado de \"dev teste\") e 20% para a validação final. Faremos isso utilizando o train_test_split(), que deverá ser importado do sklearn.model_selection.\n",
        "\n",
        "Para essa função, passaremos os dados x_zar, y_azar, e os parâmetros test_size:0,2, shuffle=True, stratify=y_azar. Nesse caso, estamos separando os 20% dos dados para validação, mesmo que o parâmetro do algorítimo se chame test_size.\n",
        "\n",
        "Essa funçã nos devolve x_train, x_test, y_train e y_test. Vamos nomear cada um desses objetos como x_treino_teste, x_validacao, y_treino_teste, y_validacao.\n",
        "\n",
        "Também precisaremos passar o SEED que nosso código seguirá. Para garantirmos que as dimensões dos dados estão separadas corretamente, imprimiremos todas aquelas variáveis na tela:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "x_treino_teste, x_validacao, y_treino_teste, y_validacao = train_test_split(x_azar, y_azar, test_size=0.2, shuffle=True, stratify=y_azar)\n",
        "\n",
        "print(x_treino_teste.shape)\n",
        "print(x_validacao.shape)\n",
        "print(y_treino_teste.shape)\n",
        "print(y_validacao.shape)COPIAR CÓDIGO\n",
        "Como retorno, teremos:\n",
        "\n",
        "(8000, 3) (2000, 3) (8000,) (2000,)\n",
        "\n",
        "Ou seja, temos:\n",
        "\n",
        "8.000 elementos e 3 colunas para treino do algorítimo\n",
        "2.000 elementos para teste\n",
        "1 coluna para verificar as features e a classe do algorítimo\n",
        "Agora, na função busca.fit(), deveremos passar as variáveis atualizadas (x_treino_teste e y_treino_teste). Também devemos nos atentar ao StratifiedShuffleSplit(): estamos passando test_size=0.2, mas 20% de 80% são 16%. Na verdade, precisamos atribuir test_size=0.25, ou seja, 25%.\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\" : randint(10, 101),\n",
        "    \"max_depth\" : randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\" : [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25)\n",
        "\n",
        "tic = time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    n_iter = 5,\n",
        "                    cv = split)\n",
        "busca.fit(x_treino_teste, y_treino_teste)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()COPIAR CÓDIGO\n",
        "Agora podemos validar nossos estimadores com os dados que encontramos. A maneira mais simples de fazer isso é com o cross_val_score(), utilizando split ao invés de KFold. Além disso, passaremos x_validacao e y_validacao ao invés de x_azar e y_azar:\n",
        "\n",
        "tic = time.time()\n",
        "scores = cross_val_score(busca, x_validacao, y_validacao, cv = split)\n",
        "tac = time.time()\n",
        "tempo_passado = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_passado)\n",
        "\n",
        "scoresCOPIAR CÓDIGO\n",
        "Tempo 0.57 segundos\n",
        "\n",
        "array([0.774])\n",
        "\n",
        "O resultado é um único 0.074 - como só tivemos um teste e uma validação, removemos a impressão da média e do intervalo.\n",
        "\n",
        "O cross validation é um processo bastante interessante e prático, e inclusive poderíamos criar um pipeline que o fizesse de uma só vez. Porém, quando existem motivos para não utilizarmos o cross validation, devemos nos atentar a alguns detalhes importantes - por exemplo, à perda do intervalo de resultados.\n",
        "\n",
        "Existem alternativas para fazer a separação dos dados em três grupos, como utilizar o Numpy ou fazer a estratificação manualmente. Na prática, preferimos utilizar o train_test_split() do próprio SKLearn para separar os dados de validação.\n",
        "\n",
        "Nós ainda poderíamos rodar o algorítimo StratifiedShuffleSplit() mais de uma vez (n_splits=5, por exemplo), obtendo resultados mais parecidos com um processo de cross validation - inclusive com diversos scores para analisarmos. Porém, as proporções podem ser diferentes, o que exigiria alguns cuidados."
      ],
      "metadata": {
        "id": "wYHSYkOf-VRI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hce1Ep0g1pUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJFgPfpy1pCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sU3ao6nd1o-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ztyXzPW1o6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkkvkllW1o3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fL6uB1Zf1ozq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}